<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jason&#39;s blog</title>
  
  <subtitle>We are in the same story.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.mazhixian.me/"/>
  <updated>2018-03-11T11:27:50.522Z</updated>
  <id>http://www.mazhixian.me/</id>
  
  <author>
    <name>Jason Ma</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>二分类及AUC的理解</title>
    <link href="http://www.mazhixian.me/2018/03/11/understanding-of-auc-curve/"/>
    <id>http://www.mazhixian.me/2018/03/11/understanding-of-auc-curve/</id>
    <published>2018-03-11T05:36:59.000Z</published>
    <updated>2018-03-11T11:27:50.522Z</updated>
    
    <content type="html"><![CDATA[<p>在机器学习中，二分类 (binary classification) 问题是最常出现且最经典的问题。本文首先解释二分类的样本标签问题，包括正例 (Positive)/反例 (Negative) 和真例 (True)/假例 (False) 这两组集合；紧接着介绍几种常用的分类器评估指标，例如精确度 (precision)、准确率 (accuracy)、敏感性 (sensitivity)、特异性 (specificity)等；最后，讨论对ROC曲线及其衍生的AUC指标的理解，并给出样例。</p><h4 id="二分类标签"><a href="#二分类标签" class="headerlink" title="二分类标签"></a>二分类标签</h4><p>应用于二分类的样本通常用正例 (Positive, P) 和反例 (Negative, N) 进行标注，作为实际标签。而经过分类器估计后的输出，根据其结果的正确与否，划分为真例 (True, T) 和假 (False)两个集合。因此，需要注意的是<code>T</code>和<code>F</code>两个集合均包含正例和反例样本。</p><p>根据实际标签和预测结果进行两两组合，得到四个子集，分别为真正率 (True positive, TP)、真反例 (True negative, TN)、假正率 (False positive, FP) 和假反例 (False negative, FN)，如下表所示。</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">预测正例</th><th style="text-align:center">预测反例</th></tr></thead><tbody><tr><td style="text-align:center">实际正例</td><td style="text-align:center">TP</td><td style="text-align:center">FN</td></tr><tr><td style="text-align:center">实际反例</td><td style="text-align:center">FP</td><td style="text-align:center">TN</td></tr></tbody></table></div><p>通过对这四个子集样本的组合，可以得到一些评估指标，用于评价分类器的表现。这里我想强调一下对FN和FP的理解，其中FN指的是<em>实际为反例，但被分类器判断为正例</em>，而FP指的是<em>实际为正例，但被分类器判断为反例</em>，二者的合集为<code>F</code>。</p><h4 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h4><p>下面讨论常用的二分类器的评估指标 (index or measure)。定义<script type="math/tex">S</script>为所有的样本数量，<script type="math/tex">S_{P}</script>和<script type="math/tex">S_{N}</script>对应实际标注为正例和反例的样本数；<script type="math/tex">S_{T}</script>和<script type="math/tex">S_{F}</script>表示分类器估计的标签中正确和错误的样本数。相应的，定义<script type="math/tex">S_{\mathrm{TP}}</script>、<script type="math/tex">S_{\mathrm{TN}}</script>、<script type="math/tex">S_{\mathrm{FP}}</script>和<script type="math/tex">S_{\mathrm{FN}}</script>为TP、TN、FP、FN样本的数目。因此，定义如下的评估指标</p><ul><li><p>准确率 (accuracy)<br>准确率为分类器预测结果中判断正确的样本占所有样本的比例，即<script type="math/tex">\mathrm{acc} = S_{T}/S = (S_{\mathrm{TP}} + \mathrm{TN}) / S</script>.</p></li><li><p>精确度 (precision)<br>精确度又称为查准率，衡量分类器预测为正的样本中实际为正例的样本比例，即 <script type="math/tex">\mathrm{pre} = S_{\mathrm{TP}} / (S_{\mathrm{TP}} + S_{\mathrm{FP}})</script>.</p></li><li><p>敏感性 (sensitivity)<br>敏感性又称为召回率或真正率，衡量实际为正例的样本经过分类器预测后标记正确的样本所占比例，即<script type="math/tex">\mathrm{sen} = S_{\mathrm{TP}} / (S_{\mathrm{TP}} + S_{\mathrm{FN}})</script>.</p></li><li><p>F1-score<br>F1-score是对精确度和敏感性的结合，因为这两者本质上是矛盾的，通常敏感性越高则精确度会较低。F1-score的表达式为, <script type="math/tex">\mathrm{F1} = (2 \times \mathrm{pre} \times \mathrm{sen}) / (\mathrm{pre} + \mathrm{sen})</script>.</p></li><li><p>特异性 (specificity)<br>特异性是实际标注为反例的样本经过分类器预测正确的样本的比例，即<script type="math/tex">\mathrm{spe} = S_\mathrm{TN} / (S_\mathrm{FN} + S_\mathrm{TN})</script>.</p></li><li><p>假正率 (fasle positive rate)<br>假正率表示分类器预测为反例的样本中实际为反例的样本的比例，即<script type="math/tex">\mathrm{fpr} = S_\mathrm{TN} / (S_\mathrm{FP} + S_\mathrm{TN})</script>.</p></li></ul><p>对于这些评估指标，我的理解见下表，</p><div class="table-container"><table><thead><tr><th style="text-align:center">评估指标</th><th style="text-align:center">意义</th></tr></thead><tbody><tr><td style="text-align:center">准确率</td><td style="text-align:center">衡量了分类器总体上的准确性，不考虑样本的实际类别.</td></tr><tr><td style="text-align:center">精确度</td><td style="text-align:center">衡量了正例的分类准确性，通常比准确率要高.</td></tr><tr><td style="text-align:center">敏感性</td><td style="text-align:center">衡量了分类器对正例的泛化能力，在异常检测中应用较多.</td></tr><tr><td style="text-align:center">特异性</td><td style="text-align:center">衡量了分类器对反例的分类准确性.</td></tr><tr><td style="text-align:center">假正率</td><td style="text-align:center">与敏感性类似，衡量分类器对反例的泛化能力.</td></tr></tbody></table></div><h4 id="ROC和AUC"><a href="#ROC和AUC" class="headerlink" title="ROC和AUC"></a>ROC和AUC</h4><p>以上的评估指标均要求分类器的输出为确定的标签，而分类器通常输出的是样本被判断为正例的概率，为了得到标签，需要设定概率的门限，即大于该门限的概率对应的样本判断为正例，否则为反例。门限的设定，影响分类器的泛化能力。</p><p>因此，人们提出了receiver operating characteristic (ROC) 的概念，最早出现二战时检测敌机的雷达分析技术。在信号处理中，有这样一组指标，即捕获率 (catch rate) 和追踪率 (follow rate)，前者衡量了系统对于目标信号的捕获能力，后者衡量系统在捕获信号后继续追踪的能力。这两个指标，对应到二分类问题中就是敏感性或真正率 (truu positive rate, TPR)和假正率。</p><p>通过TPR和FRP即可求解ROC曲线。对分类器输出的样本概率进行排序，设定概率门限<code>thrs</code>，将高于该门限的样本判断为正例，反之判断为反例。而后，与实际的样本标签进行比较，计算对应该门限的TPR和FPR。记录不同门限处的TPR和FRP，则得到了该分类器的ROC曲线。</p><p>如下为ROC曲线的求解算法，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Step1. input labels and probs estimated by classifier;</div><div class="line">Step2. set thresholding step</div><div class="line">Step3. for thrs = 1.0 : step : 0.0</div><div class="line">labels_est = zeros(size(labels))</div><div class="line">        labels_Est[probs &gt; thrs] = 1</div><div class="line">        calculate fpr and tpr w.r.t. thrs</div><div class="line">Step4. Draw the ROC curve</div></pre></td></tr></table></figure></p><p>针对不同的分类器，若某个分类器的ROC曲线整体在其他分类器的上方，则可认为该分类器最优。但往往存在ROC曲线交叉的情形，此时通过计算ROC曲线下方的面积，即AUC (area under curve)值来进行对比，AUC数值越大，分类器的分类效果越好，泛化能力越强。</p><p>给出一个ROC曲线和AUC的求解样例，具体的代码实现见<a href="https://github.com/myinxd/canal-notebooks/blob/master/machinelearning/notebook-roc-auc.ipynb" target="_blank" rel="external">这里</a>.</p><p>首先，设样本的标签和二分类器输出的概率为，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">labels = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]</div><div class="line">probs = [<span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.2</span>, <span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.3</span>, <span class="number">0.9</span>, <span class="number">0.5</span>]</div></pre></td></tr></table></figure></p><p>设定thrs的步长为0.1，则求解的TPR和FPR分别为，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tpr = [<span class="number">0.0</span>, <span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]</div><div class="line">fpr = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.33</span>, <span class="number">0.33</span>, <span class="number">0.67</span>, <span class="number">0.83</span>, <span class="number">1.0</span>]</div></pre></td></tr></table></figure></p><p>最后，求解得到auc=0.967. 下图为该样例的ROC曲线，</p><center><img src="https://github.com/myinxd/canal-notebooks/blob/master/machinelearning/fig_roc.png?raw=true" height="250" width="360"></center><p><a href="https://www.scikit-learn.org" target="_blank" rel="external">scikit-learn</a>也提供了求解auc的函数，其用法如下，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line">fpr, tpr, thresholds = metrics.roc_curve(labels+<span class="number">1</span>, p, pos_label=<span class="number">2</span>)</div><div class="line">auc = metrics.auc(fpr, tpr)</div></pre></td></tr></table></figure></p><p>在我的notebook中，分别给出了我的实现和sklearn.metrics.auc的实现，二者结果相同。最后吐个槽，因为haroopad的bug，这篇是我重新写的！！！</p><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] 周志华，机器学习，2017 清华大学出版社<br>[2] <a href="https://www.zhihu.com/question/39840928" target="_blank" rel="external">机器学习和统计里面的auc怎么理解？</a><br>[3] <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html" target="_blank" rel="external">sklearn.metrics.auc</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在机器学习中，二分类 (binary classification) 问题是最常出现且最经典的问题。本文首先解释二分类的样本标签问题，包括正例 (Positive)/反例 (Negative) 和真例 (True)/假例 (False) 这两组集合；紧接着介绍几种常用的分类
      
    
    </summary>
    
    
      <category term="machine-learning" scheme="http://www.mazhixian.me/all-tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>SVM hyperplane visualization based on libsvm</title>
    <link href="http://www.mazhixian.me/2018/03/06/svm-hyperplane-visualization-based-on-libsvm/"/>
    <id>http://www.mazhixian.me/2018/03/06/svm-hyperplane-visualization-based-on-libsvm/</id>
    <published>2018-03-06T01:24:10.000Z</published>
    <updated>2018-03-06T03:19:10.224Z</updated>
    
    <content type="html"><![CDATA[<p>Support vector machine (SVM), as a shallow model, has been widely applied for classification tasks. To solve the model, groups of super vectors (SVs) of corresponding classes are extracted, so as to calculate a hyperplane as the classification boarder.</p><h3 id="A-brief-review"><a href="#A-brief-review" class="headerlink" title="A brief review"></a>A brief review</h3><p>Denote <script type="math/tex">\mathbf{x} = \{\mathbf{x_1},~\mathbf{x_2},~\dots,~\mathbf{x_N}\}</script> as the samples to be classified, and $y = \{y_1,~y_2,~\dots,~y_N\}$ are the corresponding labels. Take binary classification as an example, </p><script type="math/tex; mode=display">\begin{equation}    y_i(\mathbf{w}\cdot\mathbf{x_i}+b) \geq 1, i = 1,~2,~\dots,~N,\end{equation}</script><p>where <script type="math/tex">\mathbf{w}</script> are the coefficients w.r.t. features in <script type="math/tex">\mathbf{x}</script>, b is the bias.</p><p>The the problem becomes an optimization task, where the object is,</p><script type="math/tex; mode=display">\begin{equation}\begin{cases}    \min\limits_{w}\frac{\left \| \mathbf{w} \right \|}{2}, \\    \mathrm{s.t.}~y_i(\mathbf{w}\cdot\mathbf{x_i}+b) \geq 1, i = 1,~2,~\dots,~N,\end{cases}\end{equation}</script><p>which shall be calculated with Lagrange equation,</p><script type="math/tex; mode=display">\begin{equation}L_P = \frac{1}{2}{\left\| \mathbf{w} \right \|} - \sum^{N}_{i=1}{\lambda_i\{y_i(\mathbf{w}\cdot\mathbf{x_i}+b)-1\}}.\end{equation}</script><p>To save time, it usually selects a subset of <script type="math/tex">\mathbf{x}</script> namely super vectors to optimize above equation, instead of all of the samples. Those SVs are samples that stand close to the classification hyperplane, i.e., the boarders of different types. They are considered on behalf of the classes they belonging to.</p><p>By solving the Lagrange equation, we obtain the <script type="math/tex">\mathbf{\lambda}</script>, as well as <script type="math/tex">\mathbf{w}</script> and $b$.</p><script type="math/tex; mode=display">\begin{equation}\begin{cases}    \mathbf{w} = \sum^{N_\rm{SV}}_{i=1}{\lambda_i y_i \mathbf{x_i}}, \\    b = - \frac{1}{2}\mathbf{w}\cdot(\mathbf{x_{c1}}+\mathbf{x_{c2}}),\end{cases}\end{equation}</script><p>where <script type="math/tex">\mathbf{x_c1}</script> and <script type="math/tex">\mathbf{x_c2}</script> are arbitrary super vectors of class one and two, respectively.</p><p>The dicision function based on those parameters are,</p><script type="math/tex; mode=display">\begin{equation}    f(\mathbf{x_s}) = \rm{sgn}\left[ \sum^{N_\rm{SV}}_{i=1}{\lambda_i y_i (\mathbf{x_i}\cdot\mathbf{x_s}) + b} \right],\end{equation}</script><p>here <script type="math/tex">\rm{sgn}</script> is the sign function.</p><p>For non-linear classification, which is more general than linear case, the dot product between <script type="math/tex">\mathbf{x_i}</script> and <script type="math/tex">\mathbf{x_s}</script> are replaced by non-linear kernel functions $\Phi(\cdot)$, i.e.,</p><script type="math/tex; mode=display">\begin{equation}    f(\mathbf{x_s}) = \rm{sgn}\left[ \sum^{N_\rm{SV}}_{i=1}{\lambda_i y_i \Phi(\mathbf{x_i},\mathbf{x_s})+b} \right].\end{equation}</script><h3 id="Realization-and-visualization"><a href="#Realization-and-visualization" class="headerlink" title="Realization and visualization"></a>Realization and visualization</h3><p>With the help of <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank" rel="external">libsvm</a>, it is easy to realize SVM based classification. What I want to say in this blog is how to visualize or replicate the prediction stage of the <code>svmtrain</code> function. Some comments are as follows,</p><ul><li>After training the SVM with <code>svmtrain</code>, a <code>model</code> will be generated;</li><li>In the <code>model</code>, super vectors, parameters like weights and bias, are archived;</li><li><strong>To save space, the support vectors are saved as sparse matrix.</strong></li><li>For multi-class classification, it can be transformed to multiple binary-classification tasks.</li></ul><p>Here is a naive two-dimensional three-type classification example (<a href="https://github.com/myinxd/svm-toy/blob/master/demos/DrawSepLine3C.m" target="_blank" rel="external">code</a> is available). I divided three-class task into three binary classifications. The linear kernel function was used, thus the classification hyperplanes were also linear.</p><p><center><img src="https://github.com/myinxd/svm-toy/raw/master/images/fig_3c.png?raw=true" height="280" width="600"></center><br>In the right figure, only support vector points are plotted. It can be found that the SVs are those points stand at the boarder between different categories.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Support vector machine (SVM), as a shallow model, has been widely applied for classification tasks. To solve the model, groups of super v
      
    
    </summary>
    
    
      <category term="MATLAB" scheme="http://www.mazhixian.me/all-tags/MATLAB/"/>
    
  </entry>
  
  <entry>
    <title>Nupy矩阵的复制问题</title>
    <link href="http://www.mazhixian.me/2018/03/04/a-numpy-matrix-copy-problem/"/>
    <id>http://www.mazhixian.me/2018/03/04/a-numpy-matrix-copy-problem/</id>
    <published>2018-03-04T02:26:23.000Z</published>
    <updated>2018-03-04T02:46:30.801Z</updated>
    
    <content type="html"><![CDATA[<p>简单记录一下最近遇到的一个bug，利用numpy生成的矩阵在复制时不能直接赋值，而是要用<code>copy</code>方法。直接赋值类似于把内存中的地址 (即指针) 给了目标变量，其与被赋值变量共享同一块内存，这样做可以节省内存空间。而<code>copy</code>则不同，会重新申请一块内存，分配给复制后的新变量，在该变量上的操作不会对愿变量产生影响。</p><p>下面看一个例子,<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">x = np.arange(<span class="number">9.</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</div><div class="line"><span class="comment"># copy</span></div><div class="line">y = x.copy()</div><div class="line">y[y&gt;=<span class="number">5</span>] = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="comment"># 赋值法</span></div><div class="line">z = x</div><div class="line">z[z&gt;=<span class="number">5</span>] = <span class="number">0</span></div></pre></td></tr></table></figure></p><p>其输出结果如下,<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">In [<span class="number">6</span>]: y</div><div class="line">Out[<span class="number">6</span>]: </div><div class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</div><div class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>],</div><div class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</div><div class="line"></div><div class="line">In [<span class="number">7</span>]: x</div><div class="line">Out[<span class="number">7</span>]: </div><div class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</div><div class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</div><div class="line">       [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</div><div class="line"></div><div class="line">In [<span class="number">8</span>]: z</div><div class="line">Out[<span class="number">8</span>]: </div><div class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</div><div class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>],</div><div class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</div><div class="line"></div><div class="line">In [<span class="number">9</span>]: x</div><div class="line">Out[<span class="number">9</span>]: </div><div class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</div><div class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>],</div><div class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</div></pre></td></tr></table></figure></p><p>可以看到，采用<code>copy</code>后，对<code>y</code>的操作不会影响到原矩阵<code>x</code>，而采用直接赋值后，对<code>z</code>的操作对<code>x</code>产生了影响。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;简单记录一下最近遇到的一个bug，利用numpy生成的矩阵在复制时不能直接赋值，而是要用&lt;code&gt;copy&lt;/code&gt;方法。直接赋值类似于把内存中的地址 (即指针) 给了目标变量，其与被赋值变量共享同一块内存，这样做可以节省内存空间。而&lt;code&gt;copy&lt;/code&gt;
      
    
    </summary>
    
    
      <category term="python" scheme="http://www.mazhixian.me/all-tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Upgrade Ubuntu from 1610 to 1710</title>
    <link href="http://www.mazhixian.me/2018/02/28/upgrade-ubuntu-from-1610-to-1710/"/>
    <id>http://www.mazhixian.me/2018/02/28/upgrade-ubuntu-from-1610-to-1710/</id>
    <published>2018-02-28T02:59:38.000Z</published>
    <updated>2018-02-28T03:19:56.626Z</updated>
    
    <content type="html"><![CDATA[<p>考虑到系统的稳定性，也因为懒，一直没升级Ubuntu 1610，也没有update。最近发现官方已经不支持1610了，而且直接把<code>yakkety</code>的镜像给取消了。所以，即使是利用系统自带的update manager，也无法直接升级到1710，会出现如下的两类错误，</p><h5 id="无法更新"><a href="#无法更新" class="headerlink" title="无法更新"></a>无法更新</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">E:The repository <span class="string">'http://archive.canonical.com/ubuntu yakkety Release'</span> does not have a Release file., </div><div class="line">W:Updating from such a repository can<span class="string">'t be done securely, and is therefore disabled by default., </span></div><div class="line"><span class="string">W:See apt-secure(8) manpage for repository creation and user configuration details., </span></div><div class="line"><span class="string">E:The repository '</span>http://archive.ubuntu.com/ubuntu yakkety Release<span class="string">' does not have a Release file., </span></div><div class="line"><span class="string">W:Updating from such a repository can'</span>t be <span class="keyword">done</span> securely, and is therefore disabled by default., </div><div class="line">W:See apt-secure(8) manpage <span class="keyword">for</span> repository creation and user configuration details., </div><div class="line">E:The repository <span class="string">'http://archive.ubuntu.com/ubuntu yakkety-updates Release'</span> does not have a Release file., </div><div class="line">...</div></pre></td></tr></table></figure><h5 id="无法升级"><a href="#无法升级" class="headerlink" title="无法升级"></a>无法升级</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">An upgrade from <span class="string">'yakkety'</span> to <span class="string">'artful'</span> is not supported with this tool.</div></pre></td></tr></table></figure><p>参考Askubuntu上的<a href="https://askubuntu.com/questions/997047/how-to-update-ubuntu-from-16-10-to-17-10" target="_blank" rel="external">问题</a>，有如下的解决方法，<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /etc/apt/</div><div class="line"><span class="comment"># 备份现有的sources.list</span></div><div class="line">sudo cp sources.list sources.list.bkp</div><div class="line"><span class="comment"># 替换yakkety为artful</span></div><div class="line">sudo vim sources.list</div><div class="line">:%s/yakkety/artful/g</div><div class="line"><span class="comment"># 保存并重新更新和升级</span></div><div class="line">sudo update</div><div class="line">sudo upgrade</div><div class="line"><span class="comment"># 重启系统</span></div><div class="line">reboot</div></pre></td></tr></table></figure></p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] <a href="https://askubuntu.com/questions/997047/how-to-update-ubuntu-from-16-10-to-17-10" target="_blank" rel="external">How to upgrade ubuntu from 1610 to 1710</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;考虑到系统的稳定性，也因为懒，一直没升级Ubuntu 1610，也没有update。最近发现官方已经不支持1610了，而且直接把&lt;code&gt;yakkety&lt;/code&gt;的镜像给取消了。所以，即使是利用系统自带的update manager，也无法直接升级到1710，会出现如
      
    
    </summary>
    
    
      <category term="linux" scheme="http://www.mazhixian.me/all-tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Python和MATLAB矩阵索引的一个区别</title>
    <link href="http://www.mazhixian.me/2018/02/27/difference-of-indexing-between-python-and-matlab/"/>
    <id>http://www.mazhixian.me/2018/02/27/difference-of-indexing-between-python-and-matlab/</id>
    <published>2018-02-27T02:04:15.000Z</published>
    <updated>2018-02-27T02:36:29.198Z</updated>
    
    <content type="html"><![CDATA[<p>这两天尝试将一个MATLAB工程转成Python，卡在一个bug上很久，最后发现是二者在矩阵索引上存在区别。这里我采用的是Python的<a href="https://www.numpy.org" target="_blank" rel="external">NumPy</a>库。</p><p>我们经常会通过一定的逻辑关系索引矩阵中的元素，并获取这些元素的位置信息，即indices。例如，<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% MATLAB实现</span></div><div class="line">x = resize(<span class="number">0</span>:<span class="number">8</span>, <span class="number">3</span>, <span class="number">3</span>);</div><div class="line"><span class="comment">% 一维索引</span></div><div class="line">idx = <span class="built_in">find</span>(x &gt;= <span class="number">3</span>);</div><div class="line"><span class="comment">% 二维索引</span></div><div class="line">[idr, idc] = <span class="built_in">find</span>(x &gt;= <span class="number">3</span>);</div></pre></td></tr></table></figure></p><p>对应的python实现为，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">x = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</div><div class="line"><span class="comment"># 只有二维索引</span></div><div class="line">[idr, idc] = np.where(x &gt;= <span class="number">3</span>)</div></pre></td></tr></table></figure></p><p>这里可以看出，MATLAB提供一种一维索引，即将二维矩阵以列为先，行次之转为一维向量，输出的索引对应该一维向量中元素所在位置。（这种处理方法经常可以用于加速运算，缩短运行时间。）然而，NumPy的where方法根据矩阵的维数提供对应axis的索引，没有MATLAB这种一维索引的输出。</p><p>因此，在python中使用np.where进行矩阵元素索引时，要注意如下两点，</p><ol><li>np.where的输出是一个列表;</li><li>np.where的输出列表的元素个数与矩阵的维数对应。</li></ol><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html" target="_blank" rel="external">numpy.where</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这两天尝试将一个MATLAB工程转成Python，卡在一个bug上很久，最后发现是二者在矩阵索引上存在区别。这里我采用的是Python的&lt;a href=&quot;https://www.numpy.org&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;NumPy&lt;
      
    
    </summary>
    
    
      <category term="python" scheme="http://www.mazhixian.me/all-tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Curve fitting by SciPy</title>
    <link href="http://www.mazhixian.me/2018/02/26/Curve-fitting-by-scipy/"/>
    <id>http://www.mazhixian.me/2018/02/26/Curve-fitting-by-scipy/</id>
    <published>2018-02-26T02:09:33.000Z</published>
    <updated>2018-02-26T02:49:22.826Z</updated>
    
    <content type="html"><![CDATA[<p>简单记录一下利用python的<a href="https://www.scipy.org" target="_blank" rel="external">SciPy</a>库进行曲线拟合的方法，主要分为三个步骤，(1) 获取待拟合数据; (2) 定义函数描述待拟合曲线; （3）利用<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html" target="_blank" rel="external">Scipy.optimize.curve_fit</a>模块进行拟合。</p><p>获取数据的步骤不再赘述，这里从步骤二开始。以泊松分布为例，首先定义函数<code>poisson_func</code>，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> math</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">poisson_func</span><span class="params">(k, l, c)</span>:</span></div><div class="line"><span class="string">"""Poisson function</span></div><div class="line"><span class="string">    inputs</span></div><div class="line"><span class="string">    ======</span></div><div class="line"><span class="string">    k: np.ndarray</span></div><div class="line"><span class="string">       number of accidents, i.e., the x axis;</span></div><div class="line"><span class="string">    l: double</span></div><div class="line"><span class="string">       the lambda parameter of Poisson distribution</span></div><div class="line"><span class="string">    c: double</span></div><div class="line"><span class="string">       a constant for release the optimization</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    output</span></div><div class="line"><span class="string">    ======</span></div><div class="line"><span class="string">    the fitted result according to l and c w.r.t. k</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    note</span></div><div class="line"><span class="string">    ====</span></div><div class="line"><span class="string">    l and c are the parametres to be estimated.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    k_mat = np.ones(k.shape)</div><div class="line">    <span class="keyword">for</span> x, i <span class="keyword">in</span> enumerate(k):</div><div class="line">        k_mat[i] = math.factorial(x) </div><div class="line">    <span class="keyword">return</span> l**k / k_mat*np.exp(-l) + c</div></pre></td></tr></table></figure></p><p>紧接着，根据待拟合的数据，对参数进行估计，如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</div><div class="line"></div><div class="line">popt, pcov = curve_fit(poisson_func, x, y)</div><div class="line">perr = np.sqrt(np.diag(pcov))</div></pre></td></tr></table></figure></p><p>其中<code>popt</code>为估计的参数，<code>pcov</code>为对应的相关矩阵，其对角线为方差，可用于计算拟合参数的误差perr。</p><p>下图为我的测试样例，图中橙色三角为待拟合样本点，蓝色实线为拟合结果。</p><center><img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180226/fig1.png?raw=true" height="300" width="430"></center><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html" target="_blank" rel="external">Scipy.optimize.curve_fit</a><br>[2] <a href="https://en.wikipedia.org/wiki/Poisson_distribution" target="_blank" rel="external">Poisson distribution</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;简单记录一下利用python的&lt;a href=&quot;https://www.scipy.org&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;SciPy&lt;/a&gt;库进行曲线拟合的方法，主要分为三个步骤，(1) 获取待拟合数据; (2) 定义函数描述待拟合曲线; 
      
    
    </summary>
    
    
      <category term="python" scheme="http://www.mazhixian.me/all-tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Happy Chinese new year</title>
    <link href="http://www.mazhixian.me/2018/02/15/happy-chinese-new-year/"/>
    <id>http://www.mazhixian.me/2018/02/15/happy-chinese-new-year/</id>
    <published>2018-02-15T09:09:57.000Z</published>
    <updated>2018-02-15T09:15:34.765Z</updated>
    
    <content type="html"><![CDATA[<p>Nothing to tell, ‘cause I am out of work for a week, lol. A warm greeting from my hometown that happy Chinese new year. Also a celebrationg for my 400th contribution to my github.</p><p>Wish everything well in the new year.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Nothing to tell, ‘cause I am out of work for a week, lol. A warm greeting from my hometown that happy Chinese new year. Also a celebratio
      
    
    </summary>
    
    
      <category term="life" scheme="http://www.mazhixian.me/all-tags/life/"/>
    
  </entry>
  
  <entry>
    <title>Write a blog by Hexo</title>
    <link href="http://www.mazhixian.me/2018/02/07/write-a-blog-by-hexo/"/>
    <id>http://www.mazhixian.me/2018/02/07/write-a-blog-by-hexo/</id>
    <published>2018-02-07T14:30:21.000Z</published>
    <updated>2018-02-07T14:49:47.453Z</updated>
    
    <content type="html"><![CDATA[<p>写之前吐个槽，连续的熬夜加酗酒，要跪。。。睡前写个hexo相关的教程，基于hexo如何撰写和发布一篇博客。主要分为两步，(1) 掌握markdown语法和git相关指令; (2) 利用hexo命令初始和编译文章。</p><h4 id="Markdown语法和git相关指令"><a href="#Markdown语法和git相关指令" class="headerlink" title="Markdown语法和git相关指令"></a>Markdown语法和git相关指令</h4><p>Markdown的基本语法可以参考<a href="http://blog.sina.com.cn/s/blog_9b6253b10102x998.html" target="_blank" rel="external">这篇文章</a>，在博客中主要会用到三种语法结构，</p><ul><li>标题控制 用#，#号数量越多，标题级别越低;</li><li>超链接： 形如<code>[name](address)</code>;</li><li>图像: 形如<code>![name](address)</code> 注意感叹号。</li></ul><p>而git相关的指令，用于上传图片，作为图床。主要指令有，</p><ul><li>git add xxx : 添加一个需要push的文件;</li><li>git commit -m “xxx”: 给这次push添加commitp;</li><li>git push： 将commit的文件推送到git仓库中。</li></ul><h4 id="利用Hexo命令初始、编译和发布文章"><a href="#利用Hexo命令初始、编译和发布文章" class="headerlink" title="利用Hexo命令初始、编译和发布文章"></a>利用Hexo命令初始、编译和发布文章</h4><p>Hexo 的安装和配置参考<a href="http://www.mazhixian.me/2017/08/23/Build-your-blog/">这篇文章</a>，这里只介绍新文章的生成过程。</p><ol><li><p>新建一篇名为xxx的文章，此时在blog/source/_posts路径下会生成名为’xxx.md’的文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> blog</div><div class="line">$ hexo new <span class="string">"xxx"</span></div></pre></td></tr></table></figure></li><li><p>编写文章</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> ./<span class="built_in">source</span>/_posts</div><div class="line">$ vim xxx.md</div></pre></td></tr></table></figure></li></ol><p>或者可以利用markdown相关的编辑器，如<a href="http://pad.haroopress.com/user.html" target="_blank" rel="external">haroopad</a>，这是一款非常好用的编辑器。</p><ol><li>编译、预览和发布文章<br>利用如下命令可以编译、预览和发布文章，<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ hexo g <span class="comment"># 编译</span></div><div class="line">$ hexo s <span class="comment"># 预览，此时在浏览器输入 localhost:4000</span></div><div class="line">$ hexo d <span class="comment"># 发布文章到github</span></div></pre></td></tr></table></figure></li></ol><p>Enjoy it~~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;写之前吐个槽，连续的熬夜加酗酒，要跪。。。睡前写个hexo相关的教程，基于hexo如何撰写和发布一篇博客。主要分为两步，(1) 掌握markdown语法和git相关指令; (2) 利用hexo命令初始和编译文章。&lt;/p&gt;
&lt;h4 id=&quot;Markdown语法和git相关指令
      
    
    </summary>
    
    
      <category term="hexo" scheme="http://www.mazhixian.me/all-tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Train selected variables in tensorflow graph</title>
    <link href="http://www.mazhixian.me/2018/02/04/train-selected-variables-in-tensorflow-graph/"/>
    <id>http://www.mazhixian.me/2018/02/04/train-selected-variables-in-tensorflow-graph/</id>
    <published>2018-02-03T18:02:44.000Z</published>
    <updated>2018-02-03T18:15:17.695Z</updated>
    
    <content type="html"><![CDATA[<p>写之前吐个槽，我又把<code>tf.nn.softmax_cross_entropy_with_logits</code>的参数赋反了，折腾了一晚上。。。这篇文章主要讨论TensorFlow中训练指定变量的问题。这篇<a href="http://blog.csdn.net/shwan_ma/article/details/78881961" target="_blank" rel="external">博客</a>给了个非常巧妙的方法，简单记录一下。</p><h4 id="1-查看可训练的参数及其index"><a href="#1-查看可训练的参数及其index" class="headerlink" title="1. 查看可训练的参数及其index"></a>1. 查看可训练的参数及其index</h4><p>在<code>tf.trainiable_variables</code>里存储了可以用于训练的变量，利用如下方法可以打印出它们的信息，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">variables_names = [v.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.trainable_variables()]</div><div class="line">values = sess.run(variables_names)</div><div class="line">i = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> zip(variables_names, values):</div><div class="line">    print(i, <span class="string">"Variable: "</span>, k)</div><div class="line">    print(<span class="string">"Shape: "</span>, v.shape)</div><div class="line">    i += <span class="number">1</span></div></pre></td></tr></table></figure></p><h4 id="2-建立train-options，并为其提供不同的trainable-lists"><a href="#2-建立train-options，并为其提供不同的trainable-lists" class="headerlink" title="2. 建立train options，并为其提供不同的trainable lists"></a>2. 建立train options，并为其提供不同的trainable lists</h4><p>假设有两个loss function，分别对应网络中不同区域的变量，为了实现梯度的有效传递，可以利用如下方法，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">loss1 = ...</div><div class="line">loss2 = ...</div><div class="line">var_list1 = tf.trainable_variables()[<span class="number">0</span>:<span class="number">10</span>]</div><div class="line">var_list2 = tf.trainable_variables()[<span class="number">10</span>:]</div><div class="line">train_op1 = tf.train.AdamOptimizer(learning_rate).minimize(loss1, var_list=var_list1)</div><div class="line">train_op2 = tf.train.AdamOptimizer(learning_rate).minimize(lose2, var_list=var_list2)</div></pre></td></tr></table></figure></p><h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><p>[1] <a href="http://blog.csdn.net/shwan_ma/article/details/78881961" target="_blank" rel="external">[tensorflow] 在不同层上设置不同的学习率，fine-tuning</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;写之前吐个槽，我又把&lt;code&gt;tf.nn.softmax_cross_entropy_with_logits&lt;/code&gt;的参数赋反了，折腾了一晚上。。。这篇文章主要讨论TensorFlow中训练指定变量的问题。这篇&lt;a href=&quot;http://blog.csdn.ne
      
    
    </summary>
    
    
      <category term="deep-learning" scheme="http://www.mazhixian.me/all-tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>Transpose convolution by tensorflow--odd kernel shape</title>
    <link href="http://www.mazhixian.me/2018/01/31/transpose-convolution-by-tensorflow/"/>
    <id>http://www.mazhixian.me/2018/01/31/transpose-convolution-by-tensorflow/</id>
    <published>2018-01-31T02:07:44.000Z</published>
    <updated>2018-01-31T07:34:06.969Z</updated>
    
    <content type="html"><![CDATA[<p>The auto-encoder has been applied widely for unsupervised learning, which is usually composed of two symmetric parts namely encoder and decoder. It is easy to realize an autoencoder only with fully-connected layers, i.e., DNN, but which is not that clear in CNN. </p><p>For convolution case, the layer in the decoder maintains the shape and kernel configurations for its symmetric layer in the encoder, thus the deconvolution, or <a href="deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic">transpose convolution</a> operation will be used instead of the convolution operation.</p><p>TensorFlow provides a method namedly <code>conv2d_transpose</code> in both <code>tf.nn</code> module and <code>tf.contrib.layers</code> module, which are very convenient. However, for <code>tf.contrib.layers.conv2d_transpose</code>, if the output shape of the transpose convolutution is odd when convolution stride setting as 2, it cannot control the output shape to desired one. </p><p>For example, denote a [None, 9, 9, 1] 4D-tensor $X$, convolved by a kernel of size [3, 3] with a 2 step stride and halp padding (SAME), the output 4D tensor $y$ will be [None, 5, 5, 1]. However, the transpose convolution from y by the same parameters setting generates $x’$ into a [None, 10, 10, 1] tensor, not [None, 9, 9, 1].  </p><p>To handle this, I provide a naive but effective way, see as follows,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> tensorflow.contrib.layers <span class="keyword">as</span> layers</div><div class="line"></div><div class="line">x = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>])</div><div class="line">y = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">1</span>])</div><div class="line">kernel_size = [<span class="number">3</span>, <span class="number">3</span>]</div><div class="line">stride = <span class="number">2</span></div><div class="line"></div><div class="line">x_r = layers.conv2d_transpose(</div><div class="line">        inputs=x,</div><div class="line">        num_outputs=x.get_shape().as_list()[<span class="number">1</span>],</div><div class="line">        kernel_size=kenerl_size,</div><div class="line">        padding=<span class="string">'SAME'</span>,</div><div class="line">        stride=stride,</div><div class="line">        scope=<span class="string">'conv2d_transpose'</span></div><div class="line">        )</div><div class="line"></div><div class="line">x_r = x_r[:, <span class="number">0</span>:<span class="number">-1</span>, <span class="number">0</span>:<span class="number">-1</span>, :]</div></pre></td></tr></table></figure><p>Above solution played well in my code, though ths crop may introduce bias..</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The auto-encoder has been applied widely for unsupervised learning, which is usually composed of two symmetric parts namely encoder and d
      
    
    </summary>
    
    
      <category term="deep-learning" scheme="http://www.mazhixian.me/all-tags/deep-learning/"/>
    
  </entry>
  
</feed>
