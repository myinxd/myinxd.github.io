
<!DOCTYPE html>
<html lang="en">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Jason&#39;s blog">
    <title>Archives: 2018 - Jason&#39;s blog</title>
    <meta name="author" content="Jason Ma">
    
    
    
        <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <meta name="description" content="Valar morghulis, valar dohaeris.">
<meta property="og:type" content="blog">
<meta property="og:title" content="Jason&#39;s blog">
<meta property="og:url" content="http://www.mazhixian.me/all-archives/2018/page/3/index.html">
<meta property="og:site_name" content="Jason&#39;s blog">
<meta property="og:description" content="Valar morghulis, valar dohaeris.">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jason&#39;s blog">
<meta name="twitter:description" content="Valar morghulis, valar dohaeris.">
    
    
        
    
    
        <meta property="og:image" content="http://www.mazhixian.me/assets/images/profile.jpg"/>
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/style-pz4cc6y13wt2trzqa8l3n9v0yykr0sstdaheem7qj628nhjmhp9pfawvqawz.min.css">
    <!--STYLES END-->
    
    <script type="text/javascript">
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-112822605-1', 'auto');
        ga('send', 'pageview');
    </script>


    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?20f3bcc8683b066ff79f4e36134e3982";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/ ">Jason&#39;s blog</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="1">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="/#about">
                    <img class="sidebar-profile-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Jason Ma</h4>
                
                    <h5 class="sidebar-profile-bio"><p>We are in the same story.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/ "
                            
                            title="Home"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-categories"
                            
                            title="Categories"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="Tags"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-archives"
                            
                            title="Archives"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="Search"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="About"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/myinxd" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fa fa-lg fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto:zx@mazhixian.me" target="_blank" rel="noopener" title="Mail">
                    
                        <i class="sidebar-button-icon fa fa-lg fa-envelope-o" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/404.html"
                            
                            title="Naive"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-hourglass-start" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Naive</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="RSS"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/02/21/interview-hw-multimedia/">
                            菊花场机器学习面试记录
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-02-21T17:33:03+08:00">
	
		    Feb 21, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <h5 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h5><p>面试官负责的业务: 计算机视觉相关</p>
<p>应聘职位：机器学习，计算机视觉方向</p>
<h5 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h5><p>首先自我介绍，介绍项目背景、贡献和成果。然后具体讨论技术，面试时间约45分钟。</p>
<h4 id="问题及回答"><a href="#问题及回答" class="headerlink" title="问题及回答"></a>问题及回答</h4><h5 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h5><p>Q1. 为什么做预训练+精调，用于无监督的样本有没有直接尝试做标记以后进行有监督训练？两个数据集有什么区别？ 样本的筛选有标准吗？</p>
<ul>
<li>因为有标签的样本数量不足, 无标签的样本数量可观; 预训练可以利用海量的样本进行特征学习，精调可以有针对性的强化特征中适合分类的特征。</li>
<li>没有尝试做有监督学习，是因为此类样本的标注需要专家和公开发表。且我们认为做无监督学习是有意义的。</li>
<li>两个数据集的区别：1. 样本的质量，2. 样本的类别模糊性，3. 各个类别的样本分布不同。</li>
<li>筛选有标准：例如图像质量、样本能适用于分类器的输入要求。</li>
</ul>
<p>Q2. 有没有尝试过引入其他类别的图像，做类似于迁移学习的工作？</p>
<ul>
<li>有尝试做迁移学习，但从结果上看，只应用在已有样本集上的效果更优。</li>
<li>迁移学习的网络参数规模还是比较大的，对训练设备要求较高。我们尝试提出层数较低的网络，能有助于其被应用。</li>
</ul>
<p>Q3. 既然尝试了生成网络，VAE和GAN的相同点和区别在哪里？ 既然说GAN不好训练，为什么呢？</p>
<ul>
<li>VAE和GAN的相同之处: 1. 二者都是由两个子网络组成，2. 目的都是通过估计参数的分布，以从该分布中采样，生成新的样本。</li>
<li>VAE和GAN的区别之处: 1. GAN是从一个随机噪声中产生样本，VAE是从一个特定的低维高斯分布映射到高维的样本空间，后者的约束更强。2. 普通的GAN在训练时不容易收敛，面试官建议从KL散度的角度来分析不收敛的原因。</li>
<li>近期如WGAN等对GAN的优化，使得输入和输出的分布不一定要强相关，能够帮助网络的收敛。(面试官)</li>
</ul>
<p>Q4. 生成网络怎么衡量效果好呢？ (云核心也有问过)</p>
<ul>
<li>比较生成样本的分布与原分布的相似程度;</li>
<li>将生成的样本交给专家判断，交叉验证计算机器和专家的结论。</li>
</ul>
<p>Q5. 深度学习中，常用的避免过拟合的tricks有哪些？ </p>
<ul>
<li>常用的tricks有dropout, regularization, batch normalization, residual。难度逐渐增加，方法也越新。</li>
</ul>
<p>Q6. 正则化，L1和L2的区别是什么？</p>
<ul>
<li>L1是曼哈顿距离，L2是欧氏距离，参考这篇文章 <a href="http://www.chioka.in/differences-between-the-l1-norm-and-the-l2-norm-least-absolute-deviations-and-least-squares/" target="_blank" rel="external">http://www.chioka.in/differences-between-the-l1-norm-and-the-l2-norm-least-absolute-deviations-and-least-squares/</a></li>
<li>我理解的是，二者既然是正则项，便是用于参数复杂度约束的，也能有效避免过拟合。所以应用场景会决定应用效果。。。 (面试官表示不置可否)</li>
</ul>
<p>Q7. 激活函数的作用？可以用线性的激活函数吗？</p>
<ul>
<li>激活函数有两个作用，1. 使分类器能够求解非线性问题，2. 对输出进行约束，避免BP时的梯度爆炸。</li>
<li>线性的激活函数是不可用的，因为NN本身就是为了解决各种非线性的问题， 线性激活函数不适用这种问题。(面试官)</li>
<li>我的理解是线性激活函数，如果你真想用，也是可以的。。。</li>
</ul>
<h5 id="传统机器学习"><a href="#传统机器学习" class="headerlink" title="传统机器学习"></a>传统机器学习</h5><p>Q1. 你涉及过的传统机器学习模型有哪些？</p>
<ul>
<li>不要给自己挖坑，说你真正推导过，理解原理的。我的回答是， SVM, ANN, DF, AdaBoost，HMM.</li>
</ul>
<p>Q2. SVM的核技术是什么？怎么约束核函数的？</p>
<ul>
<li>SVM用核方法的目的是解决非线性分类超平面的求解问题，通过核技巧将本特征空间的非线性分类转化为另一个空间的线性分类问题。</li>
<li>SVM核的选择参考Mercer定理，要求该函数是半正定的，且计算一对特征向量的核函数等价于在变换后的空间中计算这对向量的点积。(还是没太懂。。。)</li>
</ul>
<p>Q3. HMM的两个假设是什么？<br>参考《统计学习方法》</p>
<ul>
<li>齐次马尔可夫性假设，即任意时刻t的状态只依赖于t-1时刻的状态，与t-1之间的状态和观测无关, <script type="math/tex">P(i_t | i_{t-1}, o_{t-1}, ..., i_1, o_1) = P(i_t | i_{t-1})</script></li>
<li>观测独立性假设: 即任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他状态和观测无关，<script type="math/tex">P(o_t | i_t, o_{t-1}, i_{t-1}, ..., o_1, i_1) = P(o_t | i_t)</script></li>
</ul>
<p>Q4. EM算法还有其他的类似的模型和应用吗？</p>
<ul>
<li>常用的有两个，KNN的求解类似于EM，以及Monte Carlo模拟的求解思路类似。</li>
</ul>
<p>Q5. AdaBoost，为什么有效果，原理是什么？<br>AdaBoost是用弱分类器的线性加权来代替强分类器。这里的强和弱指“可学习”性，即分类器通过学习以后，学习准确率相对于随机猜测的距离。AdaBoost通过迭代减少分类器在数据集上的分类误差率，从而体现出有效性。或者说Boost通过弱分类降低了整体估计的误差，或者说方差，使得置信区间更小。还有一种理解是，Boost方法提高了模型的泛化能力，从而提升了分类准确率。</p>
<h4 id="图像处理问题"><a href="#图像处理问题" class="headerlink" title="图像处理问题"></a>图像处理问题</h4><p>Q1. 既然做过分类，那么传统图像处理中有哪些特征？<br>同样的，不要给自己挖坑。。。用过哪些就说，比如我说的是GLCM, Gabor。HoG和SIFT这种很常见，也需要巩固的。</p>
<p>Q2. 为什么用Gabor效果的效果就好呢？<br>我的回答是效果好。。。其实我理解的是特征提取的目的就是找到可分性高的特征。所以要考虑怎么衡量可分性。</p>
<h4 id="Any-questions"><a href="#Any-questions" class="headerlink" title="Any questions?"></a>Any questions?</h4><ol>
<li>如果可以进来，我需要准备什么？</li>
<li>部门有哪些业务？Base在哪里？</li>
</ol>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/02/21/interview-hw-multimedia/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/02/19/launch-google-chrome-from-outside-links/">
                            Ubuntu外链打开chrome显示空白标签的问题
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-02-19T22:28:31+08:00">
	
		    Feb 19, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>也许是Ubuntu16.04以后版本，或者是google-chrome的版本问题，会出现从chrome以外的链接打开chrome后只显示空白标签的情形。</p>
<h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><p>其解决方法是给<code>google-chrome.desktop</code>配置文件的<code>Exec</code>提供<code>%U</code>的值，步骤如下<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">vim ~/.local/share/applications/google-chrome.desktop</div><div class="line"><span class="meta">#</span><span class="bash"> Find Exec and add %U</span></div><div class="line">Exec=/opt/google/chrome/chrome %U</div></pre></td></tr></table></figure></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="http://blog.csdn.net/Artprog/article/details/71076111" target="_blank" rel="external">解决Ubuntu无法从外部应用启动Chrome打开链接的问题</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/02/19/launch-google-chrome-from-outside-links/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/02/15/happy-chinese-new-year/">
                            Happy Chinese new year
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-02-15T17:09:57+08:00">
	
		    Feb 15, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>Nothing to tell, ‘cause I am out of work for a week, lol. A warm greeting from my hometown that happy Chinese new year. Also a celebrationg for my 400th contribution to my github.</p>
<p>Wish everything well in the new year.</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/02/15/happy-chinese-new-year/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/02/07/write-a-blog-by-hexo/">
                            Write a blog by Hexo
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-02-07T22:30:21+08:00">
	
		    Feb 07, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>写之前吐个槽，连续的熬夜加酗酒，要跪。。。睡前写个hexo相关的教程，基于hexo如何撰写和发布一篇博客。主要分为两步，(1) 掌握markdown语法和git相关指令; (2) 利用hexo命令初始和编译文章。</p>
<h4 id="Markdown语法和git相关指令"><a href="#Markdown语法和git相关指令" class="headerlink" title="Markdown语法和git相关指令"></a>Markdown语法和git相关指令</h4><p>Markdown的基本语法可以参考<a href="http://blog.sina.com.cn/s/blog_9b6253b10102x998.html" target="_blank" rel="external">这篇文章</a>，在博客中主要会用到三种语法结构，</p>
<ul>
<li>标题控制 用#，#号数量越多，标题级别越低;</li>
<li>超链接： 形如<code>[name](address)</code>;</li>
<li>图像: 形如<code>![name](address)</code> 注意感叹号。</li>
</ul>
<p>而git相关的指令，用于上传图片，作为图床。主要指令有，</p>
<ul>
<li>git add xxx : 添加一个需要push的文件;</li>
<li>git commit -m “xxx”: 给这次push添加commitp;</li>
<li>git push： 将commit的文件推送到git仓库中。</li>
</ul>
<h4 id="利用Hexo命令初始、编译和发布文章"><a href="#利用Hexo命令初始、编译和发布文章" class="headerlink" title="利用Hexo命令初始、编译和发布文章"></a>利用Hexo命令初始、编译和发布文章</h4><p>Hexo 的安装和配置参考<a href="http://www.mazhixian.me/2017/08/23/Build-your-blog/">这篇文章</a>，这里只介绍新文章的生成过程。</p>
<ol>
<li><p>新建一篇名为xxx的文章，此时在blog/source/_posts路径下会生成名为’xxx.md’的文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> blog</div><div class="line">$ hexo new <span class="string">"xxx"</span></div></pre></td></tr></table></figure>
</li>
<li><p>编写文章</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> ./<span class="built_in">source</span>/_posts</div><div class="line">$ vim xxx.md</div></pre></td></tr></table></figure>
</li>
</ol>
<p>或者可以利用markdown相关的编辑器，如<a href="http://pad.haroopress.com/user.html" target="_blank" rel="external">haroopad</a>，这是一款非常好用的编辑器。</p>
<ol>
<li>编译、预览和发布文章<br>利用如下命令可以编译、预览和发布文章，<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ hexo g <span class="comment"># 编译</span></div><div class="line">$ hexo s <span class="comment"># 预览，此时在浏览器输入 localhost:4000</span></div><div class="line">$ hexo d <span class="comment"># 发布文章到github</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>Enjoy it~~</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/02/07/write-a-blog-by-hexo/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/02/04/train-selected-variables-in-tensorflow-graph/">
                            Train selected variables in tensorflow graph
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-02-04T02:02:44+08:00">
	
		    Feb 04, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>写之前吐个槽，我又把<code>tf.nn.softmax_cross_entropy_with_logits</code>的参数赋反了，折腾了一晚上。。。这篇文章主要讨论TensorFlow中训练指定变量的问题。这篇<a href="http://blog.csdn.net/shwan_ma/article/details/78881961" target="_blank" rel="external">博客</a>给了个非常巧妙的方法，简单记录一下。</p>
<h4 id="1-查看可训练的参数及其index"><a href="#1-查看可训练的参数及其index" class="headerlink" title="1. 查看可训练的参数及其index"></a>1. 查看可训练的参数及其index</h4><p>在<code>tf.trainiable_variables</code>里存储了可以用于训练的变量，利用如下方法可以打印出它们的信息，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">variables_names = [v.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.trainable_variables()]</div><div class="line">values = sess.run(variables_names)</div><div class="line">i = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> zip(variables_names, values):</div><div class="line">    print(i, <span class="string">"Variable: "</span>, k)</div><div class="line">    print(<span class="string">"Shape: "</span>, v.shape)</div><div class="line">    i += <span class="number">1</span></div></pre></td></tr></table></figure></p>
<h4 id="2-建立train-options，并为其提供不同的trainable-lists"><a href="#2-建立train-options，并为其提供不同的trainable-lists" class="headerlink" title="2. 建立train options，并为其提供不同的trainable lists"></a>2. 建立train options，并为其提供不同的trainable lists</h4><p>假设有两个loss function，分别对应网络中不同区域的变量，为了实现梯度的有效传递，可以利用如下方法，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">loss1 = ...</div><div class="line">loss2 = ...</div><div class="line">var_list1 = tf.trainable_variables()[<span class="number">0</span>:<span class="number">10</span>]</div><div class="line">var_list2 = tf.trainable_variables()[<span class="number">10</span>:]</div><div class="line">train_op1 = tf.train.AdamOptimizer(learning_rate).minimize(loss1, var_list=var_list1)</div><div class="line">train_op2 = tf.train.AdamOptimizer(learning_rate).minimize(lose2, var_list=var_list2)</div></pre></td></tr></table></figure></p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><p>[1] <a href="http://blog.csdn.net/shwan_ma/article/details/78881961" target="_blank" rel="external">[tensorflow] 在不同层上设置不同的学习率，fine-tuning</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/02/04/train-selected-variables-in-tensorflow-graph/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/31/transpose-convolution-by-tensorflow/">
                            Transpose convolution by tensorflow--odd kernel shape
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-31T10:07:44+08:00">
	
		    Jan 31, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>The auto-encoder has been applied widely for unsupervised learning, which is usually composed of two symmetric parts namely encoder and decoder. It is easy to realize an autoencoder only with fully-connected layers, i.e., DNN, but which is not that clear in CNN. </p>
<p>For convolution case, the layer in the decoder maintains the shape and kernel configurations for its symmetric layer in the encoder, thus the deconvolution, or <a href="deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic">transpose convolution</a> operation will be used instead of the convolution operation.</p>
<p>TensorFlow provides a method namedly <code>conv2d_transpose</code> in both <code>tf.nn</code> module and <code>tf.contrib.layers</code> module, which are very convenient. However, for <code>tf.contrib.layers.conv2d_transpose</code>, if the output shape of the transpose convolutution is odd when convolution stride setting as 2, it cannot control the output shape to desired one. </p>
<p>For example, denote a [None, 9, 9, 1] 4D-tensor $X$, convolved by a kernel of size [3, 3] with a 2 step stride and halp padding (SAME), the output 4D tensor $y$ will be [None, 5, 5, 1]. However, the transpose convolution from y by the same parameters setting generates $x’$ into a [None, 10, 10, 1] tensor, not [None, 9, 9, 1].  </p>
<p>To handle this, I provide a naive but effective way, see as follows,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> tensorflow.contrib.layers <span class="keyword">as</span> layers</div><div class="line"></div><div class="line">x = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>])</div><div class="line">y = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">1</span>])</div><div class="line">kernel_size = [<span class="number">3</span>, <span class="number">3</span>]</div><div class="line">stride = <span class="number">2</span></div><div class="line"></div><div class="line">x_r = layers.conv2d_transpose(</div><div class="line">        inputs=x,</div><div class="line">        num_outputs=x.get_shape().as_list()[<span class="number">1</span>],</div><div class="line">        kernel_size=kenerl_size,</div><div class="line">        padding=<span class="string">'SAME'</span>,</div><div class="line">        stride=stride,</div><div class="line">        scope=<span class="string">'conv2d_transpose'</span></div><div class="line">        )</div><div class="line"></div><div class="line">x_r = x_r[:, <span class="number">0</span>:<span class="number">-1</span>, <span class="number">0</span>:<span class="number">-1</span>, :]</div></pre></td></tr></table></figure>
<p>Above solution played well in my code, though ths crop may introduce bias..</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/31/transpose-convolution-by-tensorflow/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/27/upsampling-for-2D-convolution-by-tensorflow/">
                            Upsampling for 2D convolution by tensorflow
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-27T16:56:22+08:00">
	
		    Jan 27, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>A convolutional auto-encoder is usually composed of two sysmmetric parts, i.e., the encoder and decoder. By TensorFlow, it is easy to build the encoder part using modules like <a href="https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/layers" target="_blank" rel="external">tf.contrib.layers</a> or <a href="https://www.tensorflow.org/api_docs/python/tf/nn" target="_blank" rel="external">tf.nn</a>, which encapsulate methods for convolution, downsampling, and dense operations. </p>
<p>However, as for the decoder part, TF does not provide method like <strong>upsampling</strong>, which is the reverse operation of downsampling (<code>avg_pool2, max_pool2</code>). This is because <strong>max pooling</strong> is applied more frequently than <strong>average pooling</strong>, while recover an image from max-pooled matrix is difficult for lossing of locations of the max points. </p>
<p>For the average-pooled feature maps, there is a simple way to realize upsampling without high-level API like <a href="https://keras.io" target="_blank" rel="external">keras</a>, but with basic functions of TF itself.</p>
<p>Now, suppose the input is a 4-D tenser whose shape is <code>[1, 4, 4, 1]</code> and sampling rate is <code>[1, 2, 2, 1]</code>, then the upsampled matrix is also a 4-D tenser of shape <code>[1, 8, 8, 1]</code>. Following lines can realize this operation.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">x = tf.ones([<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>])</div><div class="line">k = tf.ones([<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>]) <span class="comment"># note k.shape = [rows, cols, depth_in, depth_output]</span></div><div class="line">output_shape=[<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>]</div><div class="line">y = tf.nn.conv2d_transpose(</div><div class="line">    value=x,</div><div class="line">    filter=k,</div><div class="line">    output_shape=output_shape,</div><div class="line">    strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</div><div class="line">    padding=<span class="string">'SAME'</span></div><div class="line">        )</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(tf.global_variables_initializer())</div><div class="line">    print(sess.run(y))</div></pre></td></tr></table></figure>
<p>Then, y is the upsampled matrix.</p>
<p>You may also realize upsampling by the <code>resize_images</code> function of module<code>tf.image</code>, which is,<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">y = tf.image.resize_images(</div><div class="line">    images=x,</div><div class="line">    size=[<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>],</div><div class="line">    method=ResizeMethod.NEAREST_NEIGHBOR</div><div class="line">        )</div></pre></td></tr></table></figure></p>
<p>Enjoy yourself.</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic" target="_blank" rel="external">Transposed convolution arithmetic</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/27/upsampling-for-2D-convolution-by-tensorflow/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/27/resnet-with-tensorflow-2/">
                            Residual network II -- realization by tensorflow
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-27T09:51:45+08:00">
	
		    Jan 27, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>来填ResNet的坑，residual network的原理已经在<a href="http://www.mazhixian.me/2018/01/21/resnet-with-tensorflow/">上一篇</a>里做了介绍，这一篇来讨论如何用<a href="https://www.tensorflow.org" target="_blank" rel="external">TensorFlow</a>实现。</p>
<p>虽然TF提供了slim这个库，可以很方便地搭建网络，但考虑到移植和扩展性，还是决定用<code>tf.contrib.layers</code>的函数和tf基本的函数来写。我们知道，ResNet的核心模块是<strong>Bottleneck</strong>，如下图所示，每个bottleneck的输入会通过两条路径在输出汇聚，计算残差，作为下一层的输入。</p>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180127/fig_resnet.png?raw=true" height="150" width="450">
</center>

<p>多个botleneck组合成一个block，通常会在每个block的最后一个bottleneck进行降采样，以缩小特征图大小。</p>
<p>具体的实现可以参考我的<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook_resnet13_digit_classification.ipynb" target="_blank" rel="external">notebook</a>, 下面贴一个在手写体识别样本上的测试结果，对比了<a href="http://www.mazhixian.me/2018/01/25/how-to-apply-the-batch-normalized-net/">这篇文章</a>里讨论的DNN网络。</p>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180127/fig_bn_res_cmp.png?raw=true" height="280" width="400">
</center>

<p>可以看出ResNet的效果还是非常显著的。但是得强调一下，由于网络显著加深，训练时占用的显存资源非常大，普通的GPU非常吃力。</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/27/resnet-with-tensorflow-2/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/25/how-to-apply-the-batch-normalized-net/">
                            How to apply the batch-normalized net
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-25T10:24:59+08:00">
	
		    Jan 25, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>继续填<a href="http://www.mazhixian.me/2018/01/23/batch-normalization-with-tensorflow/">这篇文章</a>的坑，如何测试和应用包含了Batch Normalization层的网络？ 在训练过程中，每个BN层直接从输入样本中求取<code>mean</code>和<code>variance</code>量，不是通过学习获取的固定值。因此，在测试网络时，需要人工提供这两个值。</p>
<p>在BN的文章里的处理方法是，对所有参与训练的<strong>mini-batch</strong>的均值和方差进行收集，采用无偏估计的方式估计总体样本的均值和方差，来表征测试样本的均值和方差，其公式如下，</p>
<script type="math/tex; mode=display">
\begin{align}
E[x] &= E[\mu_B], \notag \\
\mathrm{Var}[x] &= \frac{m}{m-1} \cdot E[{\sigma_B}^2], \notag
\end{align}</script><p>进而，BN layer的输出定义为，</p>
<script type="math/tex; mode=display">
y = \frac{\gamma}{\sqrt{\mathrm{Var}[x]+\epsilon}}\cdot x + (\beta - \frac{\gamma E[x]}{\sqrt{\mathrm{Var}[x]+\epsilon}}).</script><p>那么有如下几个问题需要解决，</p>
<ol>
<li>训练和测试过程中如何给BN传递<code>mean</code>和<code>variance</code>？即如何在计算图上体现这一运算？</li>
<li>如何动态收集每个mini-batch的mean和variance，用于总体样本的无偏估计moving_mean, moving_variance</li>
</ol>
<p>针对以上问题，TensorFlow的解决思路是设定<code>is_training</code>这个flag，如果为真，则每个mini-batch都会计算均值和方差，训练网络; 如果为假，则进入测试流程。</p>
<h4 id="基于tf-nn-batch-normalization的底层实现"><a href="#基于tf-nn-batch-normalization的底层实现" class="headerlink" title="基于tf.nn.batch_normalization的底层实现"></a>基于tf.nn.batch_normalization的底层实现</h4><p>TF提供了<code>tf.nn.batch_normalization</code>函数从底层搭建网络，其直接参考了Ioeff\&amp;Szegdy的论文，这里需要利用<code>tf.nn.moments</code>求取mini-batch的均值和方差，详细的实现代码参考<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook-batch-norm-tf.ipynb" target="_blank" rel="external">这里</a>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'BatchNorm'</span>):  </div><div class="line">	axis = list(range(len(x.get_shape()) - <span class="number">1</span>))</div><div class="line">    mean,var = tf.nn.moments(x_h, axis)</div><div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'gamma'</span>):</div><div class="line">        gamma = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=mean.get_shape()))</div><div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'beta'</span>):</div><div class="line">        beta = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=mean.get_shape()))</div><div class="line">    y = tf.nn.batch_normalization(</div><div class="line">           x = x_h,</div><div class="line">           mean = mean,</div><div class="line">           variance = var,</div><div class="line">           offset = beta,</div><div class="line">           scale = gamma,</div><div class="line">           variance_epsilon = <span class="number">1e-5</span>,</div><div class="line">           name= <span class="string">'BN'</span>)</div></pre></td></tr></table></figure></p>
<h4 id="基于tf-contrib-layers-batch-norm的实现"><a href="#基于tf-contrib-layers-batch-norm的实现" class="headerlink" title="基于tf.contrib.layers.batch_norm的实现"></a>基于tf.contrib.layers.batch_norm的实现</h4><p>在<a href="https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/layers/batch_normalization" target="_blank" rel="external">tf.contrib.layers</a>提供了<code>batch_norm</code>方法，该方法是对<code>tf.nn.batch_normalization</code>的封装，增加了如<code>center</code>，<code>is_training</code>等变量，并对BN的基础算法做了更新，用滑动平均来实现均值和房车的估计。</p>
<p>那么，如何实现包含BN层的网络的训练和测试？ 其核心是<strong>利用is_training作为flag控制输入给BN的mean和variance的来源，以及如何将moving_mean和moving_variance</strong>加入网络的训练过程中。</p>
<p>TF官方的建议方法解释是，<br><em>Note: when training, the moving_mean and moving_variance need to be updated. By default the update ops are placed in tf.GraphKeys.UPDATE_OPS, so they need to be added as a dependency to the train_op. For example:</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</div><div class="line">  <span class="keyword">with</span> tf.control_dependencies(update_ops):</div><div class="line">    train_op = optimizer.minimize(loss)</div></pre></td></tr></table></figure></p>
<p>参考<a href="(http://ruishu.io/2016/12/27/batchnorm/">这篇博客</a>，作者对此做了更棒的解释！！！！！<br><em>When you execute an operation (such as train_step), only the subgraph components relevant to train_step will be executed. Unfortunately, the update_moving_averages operation is not a parent of train_step in the computational graph, so we will never update the moving averages!</em></p>
<p>作者的解决方法：<em>Personally, I think it makes more sense to attach the update ops to the train_step itself. So I modified the code a little and created the following training function</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</div><div class="line">    <span class="keyword">with</span> tf.control_dependencies(update_ops):</div><div class="line">        <span class="comment"># Ensures that we execute the update_ops before performing the train_step</span></div><div class="line">        train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(loss)</div><div class="line">    sess = tf.Session()</div><div class="line">    sess.run(tf.global_variables_initializer())</div></pre></td></tr></table></figure></p>
<p>以上代码在<code>tf.slim.batch_norm</code>中也有体现，<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/slim" target="_blank" rel="external">slim</a>是对tf的一个更高层的封装，利用slim实现的ResNet-v2-152可以参考<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook_resnet.ipynb" target="_blank" rel="external">这里</a>。</p>
<p>最后，贴上基于<code>tf.contrib.layers.batch_norm</code>的实现样例，更详细的实现见我的<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook-bn-test.ipynb" target="_blank" rel="external">notebook</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> tensorflow.contrib.layers <span class="keyword">as</span> layers</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'BatchNorm'</span>):  </div><div class="line">	y = layers.batch_norm(</div><div class="line">    	x_h,</div><div class="line">        center=<span class="keyword">True</span>,</div><div class="line">        scale=<span class="keyword">True</span>,</div><div class="line">        is_training=is_training)</div><div class="line">        </div><div class="line"><span class="comment"># Train step </span></div><div class="line"><span class="comment"># note: should add update_ops to the train graph</span></div><div class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</div><div class="line"><span class="keyword">with</span> tf.control_dependencies(update_ops):</div><div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</div><div class="line">        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)</div></pre></td></tr></table></figure></p>
<h4 id="MLP是否采用BN的结果对比"><a href="#MLP是否采用BN的结果对比" class="headerlink" title="MLP是否采用BN的结果对比"></a>MLP是否采用BN的结果对比</h4><p>最后，贴一个是否采用BN层的结果对比，效果还是比较显著的。但是我也发现由于我设置的网络层数和FC长度都比较可观，随着Epochs增大，BN的优势并没有那么明显了。。。</p>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180125/fig_bn_cmp.png?raw=true" height="360" width="480">
</center>

<p>Enjoy it !! 我终于把这个问题看懂了，开心</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="http://proceedings.mlr.press/v37/ioffe15.html" target="_blank" rel="external">Ioffe, S. and Szegedy, C., 2015, June. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning (pp. 448-456).</a><br>[2] <a href="http://blog.csdn.net/jiruiyang/article/details/77202674" target="_blank" rel="external">tensorflow 中batch normalize 的使用</a><br>[3] <a href="https://github.com/tensorflow/tensorflow/issues/7469" target="_blank" rel="external">docs: batch normalization usage in slim #7469</a><br>[4] <a href="https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/layers/batch_normalization" target="_blank" rel="external">tf.layers.batch_normalization</a><br>[5] <a href="http://ruishu.io/2016/12/27/batchnorm/" target="_blank" rel="external">TENSORFLOW GUIDE: BATCH NORMALIZATION</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/25/how-to-apply-the-batch-normalized-net/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/24/an-interesting-usage-of-excel-sumif-function/">
                            An interesting usage of excel sumif function
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-24T20:25:52+08:00">
	
		    Jan 24, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>新开一个Tag,关于Excel的，突然有去学VBA的想法了。。。然而作为码农，有了python和pandas，为什么还要用VBA。。。言归正传，描述一下问题，如图所示，</p>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180124/fig_excel.png?raw=true" height="200" width="300">
</center>

<p>已知A列和B列，其中A列对应ID,B列对应该ID的数值。设C列某一行为<strong>R</strong>,统计A列A2:AR中出现ID=AR的元素的行号，将B列中相应行的值相加，输出到CR单元格中。用如下算法表示，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">R &lt;-- ROW(CR)</div><div class="line">Rows &lt;-- FIND(A2:AR, AR) </div><div class="line">CR &lt;-- SUM(B(Rows))</div></pre></td></tr></table></figure></p>
<p>利用Excel自带的公式<code>SUMIF</code>可以实现以上算法，其核心是固定A2,用<code>A$2</code>表示，相应的公式则为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">=SUMIF(A$2:A2, A2, B$2:B2)</div></pre></td></tr></table></figure></p>
<p>最后，再利用excel单元格的自动填充功能，获取CR对应的运算结果。</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://baike.baidu.com/item/SUMIF%E5%87%BD%E6%95%B0/6894362" target="_blank" rel="external">SUMIF函数</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/24/an-interesting-usage-of-excel-sumif-function/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
          <li class="pagination-prev">
            <a class="btn btn--default btn--small" href="/all-archives/2018/page/2/">
              <i class="fa fa-angle-left text-base icon-mr"></i>
              <span>NEWER POSTS</span>
            </a>
          </li>
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="/all-archives/2018/page/4/">
              <span>OLDER POSTS</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
        <li class="pagination-number">page 3 of 5</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2018 Jason Ma. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-remove"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Jason Ma</h4>
        
            <div id="about-card-bio"><p>We are in the same story.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Astronomer? Software engineer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker"></i>
                <br/>
                Shanghai
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/script-peofhqjkzcghmndknakluequy1y6owxdwpaqyju9ntl9zxnk7rdolb3rjjoj.min.js"></script>
<!--SCRIPTS END--><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



    </body>
</html>
