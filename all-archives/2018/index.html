
<!DOCTYPE html>
<html lang="en">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Jason&#39;s blog">
    <title>Archives: 2018 - Jason&#39;s blog</title>
    <meta name="author" content="Jason Ma">
    
    
    
        <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <meta name="description" content="Valar morghulis, valar dohaeris.">
<meta property="og:type" content="blog">
<meta property="og:title" content="Jason&#39;s blog">
<meta property="og:url" content="http://www.mazhixian.me/all-archives/2018/index.html">
<meta property="og:site_name" content="Jason&#39;s blog">
<meta property="og:description" content="Valar morghulis, valar dohaeris.">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jason&#39;s blog">
<meta name="twitter:description" content="Valar morghulis, valar dohaeris.">
    
    
        
    
    
        <meta property="og:image" content="http://www.mazhixian.me/assets/images/profile.jpg"/>
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/style-pz4cc6y13wt2trzqa8l3n9v0yykr0sstdaheem7qj628nhjmhp9pfawvqawz.min.css">
    <!--STYLES END-->
    
    <script type="text/javascript">
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-112822605-1', 'auto');
        ga('send', 'pageview');
    </script>


    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?20f3bcc8683b066ff79f4e36134e3982";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/ ">Jason&#39;s blog</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="1">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="/#about">
                    <img class="sidebar-profile-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Jason Ma</h4>
                
                    <h5 class="sidebar-profile-bio"><p>We are in the same story.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/ "
                            
                            title="Home"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-categories"
                            
                            title="Categories"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="Tags"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-archives"
                            
                            title="Archives"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="Search"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="About"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/myinxd" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fa fa-lg fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto:zx@mazhixian.me" target="_blank" rel="noopener" title="Mail">
                    
                        <i class="sidebar-button-icon fa fa-lg fa-envelope-o" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/404.html"
                            
                            title="Naive"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-hourglass-start" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Naive</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="RSS"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/02/26/Curve-fitting-by-scipy/">
                            Curve fitting by SciPy
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-02-26T10:09:33+08:00">
	
		    Feb 26, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>简单记录一下利用python的<a href="https://www.scipy.org" target="_blank" rel="external">SciPy</a>库进行曲线拟合的方法，主要分为三个步骤，(1) 获取待拟合数据; (2) 定义函数描述待拟合曲线; （3）利用<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html" target="_blank" rel="external">Scipy.optimize.curve_fit</a>模块进行拟合。</p>
<p>获取数据的步骤不再赘述，这里从步骤二开始。以泊松分布为例，首先定义函数<code>poisson_func</code>，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> math</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">poisson_func</span><span class="params">(k, l, c)</span>:</span></div><div class="line">	<span class="string">"""Poisson function</span></div><div class="line"><span class="string">    inputs</span></div><div class="line"><span class="string">    ======</span></div><div class="line"><span class="string">    k: np.ndarray</span></div><div class="line"><span class="string">       number of accidents, i.e., the x axis;</span></div><div class="line"><span class="string">    l: double</span></div><div class="line"><span class="string">       the lambda parameter of Poisson distribution</span></div><div class="line"><span class="string">    c: double</span></div><div class="line"><span class="string">       a constant for release the optimization</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    output</span></div><div class="line"><span class="string">    ======</span></div><div class="line"><span class="string">    the fitted result according to l and c w.r.t. k</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    note</span></div><div class="line"><span class="string">    ====</span></div><div class="line"><span class="string">    l and c are the parametres to be estimated.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    k_mat = np.ones(k.shape)</div><div class="line">    <span class="keyword">for</span> x, i <span class="keyword">in</span> enumerate(k):</div><div class="line">        k_mat[i] = math.factorial(x) </div><div class="line">    <span class="keyword">return</span> l**k / k_mat*np.exp(-l) + c</div></pre></td></tr></table></figure></p>
<p>紧接着，根据待拟合的数据，对参数进行估计，如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</div><div class="line"></div><div class="line">popt, pcov = curve_fit(poisson_func, x, y)</div><div class="line">perr = np.sqrt(np.diag(pcov))</div></pre></td></tr></table></figure></p>
<p>其中<code>popt</code>为估计的参数，<code>pcov</code>为对应的相关矩阵，其对角线为方差，可用于计算拟合参数的误差perr。</p>
<p>下图为我的测试样例，图中橙色三角为待拟合样本点，蓝色实线为拟合结果。</p>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180226/fig1.png?raw=true" height="300" width="430">
</center>

<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html" target="_blank" rel="external">Scipy.optimize.curve_fit</a><br>[2] <a href="https://en.wikipedia.org/wiki/Poisson_distribution" target="_blank" rel="external">Poisson distribution</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/02/26/Curve-fitting-by-scipy/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/02/15/happy-chinese-new-year/">
                            Happy Chinese new year
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-02-15T17:09:57+08:00">
	
		    Feb 15, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>Nothing to tell, ‘cause I am out of work for a week, lol. A warm greeting from my hometown that happy Chinese new year. Also a celebrationg for my 400th contribution to my github.</p>
<p>Wish everything well in the new year.</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/02/15/happy-chinese-new-year/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/02/07/write-a-blog-by-hexo/">
                            Write a blog by Hexo
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-02-07T22:30:21+08:00">
	
		    Feb 07, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>写之前吐个槽，连续的熬夜加酗酒，要跪。。。睡前写个hexo相关的教程，基于hexo如何撰写和发布一篇博客。主要分为两步，(1) 掌握markdown语法和git相关指令; (2) 利用hexo命令初始和编译文章。</p>
<h4 id="Markdown语法和git相关指令"><a href="#Markdown语法和git相关指令" class="headerlink" title="Markdown语法和git相关指令"></a>Markdown语法和git相关指令</h4><p>Markdown的基本语法可以参考<a href="http://blog.sina.com.cn/s/blog_9b6253b10102x998.html" target="_blank" rel="external">这篇文章</a>，在博客中主要会用到三种语法结构，</p>
<ul>
<li>标题控制 用#，#号数量越多，标题级别越低;</li>
<li>超链接： 形如<code>[name](address)</code>;</li>
<li>图像: 形如<code>![name](address)</code> 注意感叹号。</li>
</ul>
<p>而git相关的指令，用于上传图片，作为图床。主要指令有，</p>
<ul>
<li>git add xxx : 添加一个需要push的文件;</li>
<li>git commit -m “xxx”: 给这次push添加commitp;</li>
<li>git push： 将commit的文件推送到git仓库中。</li>
</ul>
<h4 id="利用Hexo命令初始、编译和发布文章"><a href="#利用Hexo命令初始、编译和发布文章" class="headerlink" title="利用Hexo命令初始、编译和发布文章"></a>利用Hexo命令初始、编译和发布文章</h4><p>Hexo 的安装和配置参考<a href="http://www.mazhixian.me/2017/08/23/Build-your-blog/">这篇文章</a>，这里只介绍新文章的生成过程。</p>
<ol>
<li><p>新建一篇名为xxx的文章，此时在blog/source/_posts路径下会生成名为’xxx.md’的文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> blog</div><div class="line">$ hexo new <span class="string">"xxx"</span></div></pre></td></tr></table></figure>
</li>
<li><p>编写文章</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> ./<span class="built_in">source</span>/_posts</div><div class="line">$ vim xxx.md</div></pre></td></tr></table></figure>
</li>
</ol>
<p>或者可以利用markdown相关的编辑器，如<a href="http://pad.haroopress.com/user.html" target="_blank" rel="external">haroopad</a>，这是一款非常好用的编辑器。</p>
<ol>
<li>编译、预览和发布文章<br>利用如下命令可以编译、预览和发布文章，<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ hexo g <span class="comment"># 编译</span></div><div class="line">$ hexo s <span class="comment"># 预览，此时在浏览器输入 localhost:4000</span></div><div class="line">$ hexo d <span class="comment"># 发布文章到github</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>Enjoy it~~</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/02/07/write-a-blog-by-hexo/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/02/04/train-selected-variables-in-tensorflow-graph/">
                            Train selected variables in tensorflow graph
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-02-04T02:02:44+08:00">
	
		    Feb 04, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>写之前吐个槽，我又把<code>tf.nn.softmax_cross_entropy_with_logits</code>的参数赋反了，折腾了一晚上。。。这篇文章主要讨论TensorFlow中训练指定变量的问题。这篇<a href="http://blog.csdn.net/shwan_ma/article/details/78881961" target="_blank" rel="external">博客</a>给了个非常巧妙的方法，简单记录一下。</p>
<h4 id="1-查看可训练的参数及其index"><a href="#1-查看可训练的参数及其index" class="headerlink" title="1. 查看可训练的参数及其index"></a>1. 查看可训练的参数及其index</h4><p>在<code>tf.trainiable_variables</code>里存储了可以用于训练的变量，利用如下方法可以打印出它们的信息，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">variables_names = [v.name <span class="keyword">for</span> v <span class="keyword">in</span> tf.trainable_variables()]</div><div class="line">values = sess.run(variables_names)</div><div class="line">i = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> zip(variables_names, values):</div><div class="line">    print(i, <span class="string">"Variable: "</span>, k)</div><div class="line">    print(<span class="string">"Shape: "</span>, v.shape)</div><div class="line">    i += <span class="number">1</span></div></pre></td></tr></table></figure></p>
<h4 id="2-建立train-options，并为其提供不同的trainable-lists"><a href="#2-建立train-options，并为其提供不同的trainable-lists" class="headerlink" title="2. 建立train options，并为其提供不同的trainable lists"></a>2. 建立train options，并为其提供不同的trainable lists</h4><p>假设有两个loss function，分别对应网络中不同区域的变量，为了实现梯度的有效传递，可以利用如下方法，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">loss1 = ...</div><div class="line">loss2 = ...</div><div class="line">var_list1 = tf.trainable_variables()[<span class="number">0</span>:<span class="number">10</span>]</div><div class="line">var_list2 = tf.trainable_variables()[<span class="number">10</span>:]</div><div class="line">train_op1 = tf.train.AdamOptimizer(learning_rate).minimize(loss1, var_list=var_list1)</div><div class="line">train_op2 = tf.train.AdamOptimizer(learning_rate).minimize(lose2, var_list=var_list2)</div></pre></td></tr></table></figure></p>
<h3 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h3><p>[1] <a href="http://blog.csdn.net/shwan_ma/article/details/78881961" target="_blank" rel="external">[tensorflow] 在不同层上设置不同的学习率，fine-tuning</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/02/04/train-selected-variables-in-tensorflow-graph/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/31/transpose-convolution-by-tensorflow/">
                            Transpose convolution by tensorflow--odd kernel shape
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-31T10:07:44+08:00">
	
		    Jan 31, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>The auto-encoder has been applied widely for unsupervised learning, which is usually composed of two symmetric parts namely encoder and decoder. It is easy to realize an autoencoder only with fully-connected layers, i.e., DNN, but which is not that clear in CNN. </p>
<p>For convolution case, the layer in the decoder maintains the shape and kernel configurations for its symmetric layer in the encoder, thus the deconvolution, or <a href="deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic">transpose convolution</a> operation will be used instead of the convolution operation.</p>
<p>TensorFlow provides a method namedly <code>conv2d_transpose</code> in both <code>tf.nn</code> module and <code>tf.contrib.layers</code> module, which are very convenient. However, for <code>tf.contrib.layers.conv2d_transpose</code>, if the output shape of the transpose convolutution is odd when convolution stride setting as 2, it cannot control the output shape to desired one. </p>
<p>For example, denote a [None, 9, 9, 1] 4D-tensor $X$, convolved by a kernel of size [3, 3] with a 2 step stride and halp padding (SAME), the output 4D tensor $y$ will be [None, 5, 5, 1]. However, the transpose convolution from y by the same parameters setting generates $x’$ into a [None, 10, 10, 1] tensor, not [None, 9, 9, 1].  </p>
<p>To handle this, I provide a naive but effective way, see as follows,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> tensorflow.contrib.layers <span class="keyword">as</span> layers</div><div class="line"></div><div class="line">x = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>])</div><div class="line">y = tf.placeholder(tf.float32, shape=[<span class="keyword">None</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">1</span>])</div><div class="line">kernel_size = [<span class="number">3</span>, <span class="number">3</span>]</div><div class="line">stride = <span class="number">2</span></div><div class="line"></div><div class="line">x_r = layers.conv2d_transpose(</div><div class="line">        inputs=x,</div><div class="line">        num_outputs=x.get_shape().as_list()[<span class="number">1</span>],</div><div class="line">        kernel_size=kenerl_size,</div><div class="line">        padding=<span class="string">'SAME'</span>,</div><div class="line">        stride=stride,</div><div class="line">        scope=<span class="string">'conv2d_transpose'</span></div><div class="line">        )</div><div class="line"></div><div class="line">x_r = x_r[:, <span class="number">0</span>:<span class="number">-1</span>, <span class="number">0</span>:<span class="number">-1</span>, :]</div></pre></td></tr></table></figure>
<p>Above solution played well in my code, though ths crop may introduce bias..</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/31/transpose-convolution-by-tensorflow/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/27/upsampling-for-2D-convolution-by-tensorflow/">
                            Upsampling for 2D convolution by tensorflow
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-27T16:56:22+08:00">
	
		    Jan 27, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>A convolutional auto-encoder is usually composed of two sysmmetric parts, i.e., the encoder and decoder. By TensorFlow, it is easy to build the encoder part using modules like <a href="https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/layers" target="_blank" rel="external">tf.contrib.layers</a> or <a href="https://www.tensorflow.org/api_docs/python/tf/nn" target="_blank" rel="external">tf.nn</a>, which encapsulate methods for convolution, downsampling, and dense operations. </p>
<p>However, as for the decoder part, TF does not provide method like <strong>upsampling</strong>, which is the reverse operation of downsampling (<code>avg_pool2, max_pool2</code>). This is because <strong>max pooling</strong> is applied more frequently than <strong>average pooling</strong>, while recover an image from max-pooled matrix is difficult for lossing of locations of the max points. </p>
<p>For the average-pooled feature maps, there is a simple way to realize upsampling without high-level API like <a href="https://keras.io" target="_blank" rel="external">keras</a>, but with basic functions of TF itself.</p>
<p>Now, suppose the input is a 4-D tenser whose shape is <code>[1, 4, 4, 1]</code> and sampling rate is <code>[1, 2, 2, 1]</code>, then the upsampled matrix is also a 4-D tenser of shape <code>[1, 8, 8, 1]</code>. Following lines can realize this operation.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">x = tf.ones([<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>])</div><div class="line">k = tf.ones([<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>]) <span class="comment"># note k.shape = [rows, cols, depth_in, depth_output]</span></div><div class="line">output_shape=[<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>]</div><div class="line">y = tf.nn.conv2d_transpose(</div><div class="line">    value=x,</div><div class="line">    filter=k,</div><div class="line">    output_shape=output_shape,</div><div class="line">    strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</div><div class="line">    padding=<span class="string">'SAME'</span></div><div class="line">        )</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(tf.global_variables_initializer())</div><div class="line">    print(sess.run(y))</div></pre></td></tr></table></figure>
<p>Then, y is the upsampled matrix.</p>
<p>You may also realize upsampling by the <code>resize_images</code> function of module<code>tf.image</code>, which is,<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">y = tf.image.resize_images(</div><div class="line">    images=x,</div><div class="line">    size=[<span class="number">1</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>],</div><div class="line">    method=ResizeMethod.NEAREST_NEIGHBOR</div><div class="line">        )</div></pre></td></tr></table></figure></p>
<p>Enjoy yourself.</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic" target="_blank" rel="external">Transposed convolution arithmetic</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/27/upsampling-for-2D-convolution-by-tensorflow/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/27/resnet-with-tensorflow-2/">
                            Residual network II -- realization by tensorflow
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-27T09:51:45+08:00">
	
		    Jan 27, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>来填ResNet的坑，residual network的原理已经在<a href="http://www.mazhixian.me/2018/01/21/resnet-with-tensorflow/">上一篇</a>里做了介绍，这一篇来讨论如何用<a href="https://www.tensorflow.org" target="_blank" rel="external">TensorFlow</a>实现。</p>
<p>虽然TF提供了slim这个库，可以很方便地搭建网络，但考虑到移植和扩展性，还是决定用<code>tf.contrib.layers</code>的函数和tf基本的函数来写。我们知道，ResNet的核心模块是<strong>Bottleneck</strong>，如下图所示，每个bottleneck的输入会通过两条路径在输出汇聚，计算残差，作为下一层的输入。</p>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180127/fig_resnet.png?raw=true" height="150" width="450">
</center>

<p>多个botleneck组合成一个block，通常会在每个block的最后一个bottleneck进行降采样，以缩小特征图大小。</p>
<p>具体的实现可以参考我的<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook_resnet13_digit_classification.ipynb" target="_blank" rel="external">notebook</a>, 下面贴一个在手写体识别样本上的测试结果，对比了<a href="http://www.mazhixian.me/2018/01/25/how-to-apply-the-batch-normalized-net/">这篇文章</a>里讨论的DNN网络。</p>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180127/fig_bn_res_cmp.png?raw=true" height="280" width="400">
</center>

<p>可以看出ResNet的效果还是非常显著的。但是得强调一下，由于网络显著加深，训练时占用的显存资源非常大，普通的GPU非常吃力。</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/27/resnet-with-tensorflow-2/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/25/how-to-apply-the-batch-normalized-net/">
                            How to apply the batch-normalized net
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-25T10:24:59+08:00">
	
		    Jan 25, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>继续填<a href="http://www.mazhixian.me/2018/01/23/batch-normalization-with-tensorflow/">这篇文章</a>的坑，如何测试和应用包含了Batch Normalization层的网络？ 在训练过程中，每个BN层直接从输入样本中求取<code>mean</code>和<code>variance</code>量，不是通过学习获取的固定值。因此，在测试网络时，需要人工提供这两个值。</p>
<p>在BN的文章里的处理方法是，对所有参与训练的<strong>mini-batch</strong>的均值和方差进行收集，采用无偏估计的方式估计总体样本的均值和方差，来表征测试样本的均值和方差，其公式如下，</p>
<script type="math/tex; mode=display">
\begin{align}
E[x] &= E[\mu_B], \notag \\
\mathrm{Var}[x] &= \frac{m}{m-1} \cdot E[{\sigma_B}^2], \notag
\end{align}</script><p>进而，BN layer的输出定义为，</p>
<script type="math/tex; mode=display">
y = \frac{\gamma}{\sqrt{\mathrm{Var}[x]+\epsilon}}\cdot x + (\beta - \frac{\gamma E[x]}{\sqrt{\mathrm{Var}[x]+\epsilon}}).</script><p>那么有如下几个问题需要解决，</p>
<ol>
<li>训练和测试过程中如何给BN传递<code>mean</code>和<code>variance</code>？即如何在计算图上体现这一运算？</li>
<li>如何动态收集每个mini-batch的mean和variance，用于总体样本的无偏估计moving_mean, moving_variance</li>
</ol>
<p>针对以上问题，TensorFlow的解决思路是设定<code>is_training</code>这个flag，如果为真，则每个mini-batch都会计算均值和方差，训练网络; 如果为假，则进入测试流程。</p>
<h4 id="基于tf-nn-batch-normalization的底层实现"><a href="#基于tf-nn-batch-normalization的底层实现" class="headerlink" title="基于tf.nn.batch_normalization的底层实现"></a>基于tf.nn.batch_normalization的底层实现</h4><p>TF提供了<code>tf.nn.batch_normalization</code>函数从底层搭建网络，其直接参考了Ioeff\&amp;Szegdy的论文，这里需要利用<code>tf.nn.moments</code>求取mini-batch的均值和方差，详细的实现代码参考<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook-batch-norm-tf.ipynb" target="_blank" rel="external">这里</a>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'BatchNorm'</span>):  </div><div class="line">	axis = list(range(len(x.get_shape()) - <span class="number">1</span>))</div><div class="line">    mean,var = tf.nn.moments(x_h, axis)</div><div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'gamma'</span>):</div><div class="line">        gamma = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=mean.get_shape()))</div><div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'beta'</span>):</div><div class="line">        beta = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=mean.get_shape()))</div><div class="line">    y = tf.nn.batch_normalization(</div><div class="line">           x = x_h,</div><div class="line">           mean = mean,</div><div class="line">           variance = var,</div><div class="line">           offset = beta,</div><div class="line">           scale = gamma,</div><div class="line">           variance_epsilon = <span class="number">1e-5</span>,</div><div class="line">           name= <span class="string">'BN'</span>)</div></pre></td></tr></table></figure></p>
<h4 id="基于tf-contrib-layers-batch-norm的实现"><a href="#基于tf-contrib-layers-batch-norm的实现" class="headerlink" title="基于tf.contrib.layers.batch_norm的实现"></a>基于tf.contrib.layers.batch_norm的实现</h4><p>在<a href="https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/layers/batch_normalization" target="_blank" rel="external">tf.contrib.layers</a>提供了<code>batch_norm</code>方法，该方法是对<code>tf.nn.batch_normalization</code>的封装，增加了如<code>center</code>，<code>is_training</code>等变量，并对BN的基础算法做了更新，用滑动平均来实现均值和房车的估计。</p>
<p>那么，如何实现包含BN层的网络的训练和测试？ 其核心是<strong>利用is_training作为flag控制输入给BN的mean和variance的来源，以及如何将moving_mean和moving_variance</strong>加入网络的训练过程中。</p>
<p>TF官方的建议方法解释是，<br><em>Note: when training, the moving_mean and moving_variance need to be updated. By default the update ops are placed in tf.GraphKeys.UPDATE_OPS, so they need to be added as a dependency to the train_op. For example:</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</div><div class="line">  <span class="keyword">with</span> tf.control_dependencies(update_ops):</div><div class="line">    train_op = optimizer.minimize(loss)</div></pre></td></tr></table></figure></p>
<p>参考<a href="(http://ruishu.io/2016/12/27/batchnorm/">这篇博客</a>，作者对此做了更棒的解释！！！！！<br><em>When you execute an operation (such as train_step), only the subgraph components relevant to train_step will be executed. Unfortunately, the update_moving_averages operation is not a parent of train_step in the computational graph, so we will never update the moving averages!</em></p>
<p>作者的解决方法：<em>Personally, I think it makes more sense to attach the update ops to the train_step itself. So I modified the code a little and created the following training function</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</div><div class="line">    <span class="keyword">with</span> tf.control_dependencies(update_ops):</div><div class="line">        <span class="comment"># Ensures that we execute the update_ops before performing the train_step</span></div><div class="line">        train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(loss)</div><div class="line">    sess = tf.Session()</div><div class="line">    sess.run(tf.global_variables_initializer())</div></pre></td></tr></table></figure></p>
<p>以上代码在<code>tf.slim.batch_norm</code>中也有体现，<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/slim" target="_blank" rel="external">slim</a>是对tf的一个更高层的封装，利用slim实现的ResNet-v2-152可以参考<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook_resnet.ipynb" target="_blank" rel="external">这里</a>。</p>
<p>最后，贴上基于<code>tf.contrib.layers.batch_norm</code>的实现样例，更详细的实现见我的<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook-bn-test.ipynb" target="_blank" rel="external">notebook</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> tensorflow.contrib.layers <span class="keyword">as</span> layers</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'BatchNorm'</span>):  </div><div class="line">	y = layers.batch_norm(</div><div class="line">    	x_h,</div><div class="line">        center=<span class="keyword">True</span>,</div><div class="line">        scale=<span class="keyword">True</span>,</div><div class="line">        is_training=is_training)</div><div class="line">        </div><div class="line"><span class="comment"># Train step </span></div><div class="line"><span class="comment"># note: should add update_ops to the train graph</span></div><div class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</div><div class="line"><span class="keyword">with</span> tf.control_dependencies(update_ops):</div><div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</div><div class="line">        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)</div></pre></td></tr></table></figure></p>
<h4 id="MLP是否采用BN的结果对比"><a href="#MLP是否采用BN的结果对比" class="headerlink" title="MLP是否采用BN的结果对比"></a>MLP是否采用BN的结果对比</h4><p>最后，贴一个是否采用BN层的结果对比，效果还是比较显著的。但是我也发现由于我设置的网络层数和FC长度都比较可观，随着Epochs增大，BN的优势并没有那么明显了。。。</p>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180125/fig_bn_cmp.png?raw=true" height="360" width="480">
</center>

<p>Enjoy it !! 我终于把这个问题看懂了，开心</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="http://proceedings.mlr.press/v37/ioffe15.html" target="_blank" rel="external">Ioffe, S. and Szegedy, C., 2015, June. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning (pp. 448-456).</a><br>[2] <a href="http://blog.csdn.net/jiruiyang/article/details/77202674" target="_blank" rel="external">tensorflow 中batch normalize 的使用</a><br>[3] <a href="https://github.com/tensorflow/tensorflow/issues/7469" target="_blank" rel="external">docs: batch normalization usage in slim #7469</a><br>[4] <a href="https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/layers/batch_normalization" target="_blank" rel="external">tf.layers.batch_normalization</a><br>[5] <a href="http://ruishu.io/2016/12/27/batchnorm/" target="_blank" rel="external">TENSORFLOW GUIDE: BATCH NORMALIZATION</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/25/how-to-apply-the-batch-normalized-net/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/24/an-interesting-usage-of-excel-sumif-function/">
                            An interesting usage of excel sumif function
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-24T20:25:52+08:00">
	
		    Jan 24, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>新开一个Tag,关于Excel的，突然有去学VBA的想法了。。。然而作为码农，有了python和pandas，为什么还要用VBA。。。言归正传，描述一下问题，如图所示，</p>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180124/fig_excel.png?raw=true" height="200" width="300">
</center>

<p>已知A列和B列，其中A列对应ID,B列对应该ID的数值。设C列某一行为<strong>R</strong>,统计A列A2:AR中出现ID=AR的元素的行号，将B列中相应行的值相加，输出到CR单元格中。用如下算法表示，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">R &lt;-- ROW(CR)</div><div class="line">Rows &lt;-- FIND(A2:AR, AR) </div><div class="line">CR &lt;-- SUM(B(Rows))</div></pre></td></tr></table></figure></p>
<p>利用Excel自带的公式<code>SUMIF</code>可以实现以上算法，其核心是固定A2,用<code>A$2</code>表示，相应的公式则为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">=SUMIF(A$2:A2, A2, B$2:B2)</div></pre></td></tr></table></figure></p>
<p>最后，再利用excel单元格的自动填充功能，获取CR对应的运算结果。</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://baike.baidu.com/item/SUMIF%E5%87%BD%E6%95%B0/6894362" target="_blank" rel="external">SUMIF函数</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/24/an-interesting-usage-of-excel-sumif-function/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/01/24/tensorflow-graph-and-tensorboard/">
                            TensorFlow graph and TensorBoard
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-01-24T14:55:13+08:00">
	
		    Jan 24, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>继续挖坑，因为Batch normalization的inference还没有解决，不知道怎么在tf.Tensor中更新数值，参考<a href="https://www.tensorflow.org/api_docs/python/tf/layers/BatchNormalization" target="_blank" rel="external">tf.layer.BatchNormalization</a>的思路，需要利用<code>is_training</code>来选择feed给BN的<code>mean</code>和<code>variance</code>。因此，需要理解TensorFlow的<strong>graph</strong>概念。除此之外，TF提供了<a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard" target="_blank" rel="external">TensorBoard</a>作为计算图可视化的工具，也是值得借鉴的。</p>
<h3 id="计算图—Graph"><a href="#计算图—Graph" class="headerlink" title="计算图—Graph"></a>计算图—Graph</h3><p>TensorFlow是一个通过计算图的形式来表达张量之间通过计算相互转化的过程[1]。作为TensoFlow的基本概念，TF中的所有计算都会转化为计算图上的节点，节点之间的边用于描述计算之间的依赖关系。TF中不同的计算图之间维护的节点和边是独立的。通过tf.GraphKeys可以对图进行维护，稍后会介绍。</p>
<p>利用<code>tf.Graph</code>类实例化计算图，有如下的样例，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line">g1 = tf.Graph()</div><div class="line"><span class="keyword">with</span> g1.as_default():</div><div class="line">	v = tf.get_variable&#123;<span class="string">"v"</span>, initializer=tf.zeros_initializer(shape=[<span class="number">1</span>])&#125;</div></pre></td></tr></table></figure></p>
<h3 id="TensorBoard-可视化"><a href="#TensorBoard-可视化" class="headerlink" title="TensorBoard 可视化"></a>TensorBoard 可视化</h3><p>TensorBoard可以有效地展示TF在运行过程中的计算图、各种指标随时间的变化趋势以及训练中使用的图像等信息，其利用TF运行过程中输出的<strong>日志文件</strong>可视化程序的运行状态。TensorBoard和TensorFlow运行在不同的进程中，TB会自动读取TF的日志文件，并呈现当前的运行状态。根据TensorBoard的<a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard" target="_blank" rel="external">官方文档</a>，其实现过程有如下步骤，</p>
<h4 id="1-搭建网络"><a href="#1-搭建网络" class="headerlink" title="1. 搭建网络"></a>1. 搭建网络</h4><p><em>First, create the TensorFlow graph that you’d like to collect summary data from, and decide which nodes you would like to annotate with summary operations.</em></p>
<p>利用TensorFlow搭建网络，例如基于MLP的手写体识别网络，提供一个<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook_deep_mnist_for_experts_tf.ipynb" target="_blank" rel="external">样例</a>，可以参考。</p>
<h4 id="2-Select-variables-to-be-summarized"><a href="#2-Select-variables-to-be-summarized" class="headerlink" title="2. Select variables to be summarized"></a>2. Select variables to be summarized</h4><p>通常我们关注训练过程中待学习的参数 (如weights, biases等) 的变化和收敛情况，通过<code>tf.summary.scalar</code>和<code>tf.summary.histogram</code>可以很方便地收集这些数据。下面给出一个样例，参考了[3]，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">variable_summaries</span><span class="params">(var)</span>:</span></div><div class="line">  <span class="string">"""Attach a lot of summaries to a Tensor (for TensorBoard visualization)."""</span></div><div class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'summaries'</span>):</div><div class="line">    mean = tf.reduce_mean(var)</div><div class="line">    tf.summary.scalar(<span class="string">'mean'</span>, mean)</div><div class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'stddev'</span>):</div><div class="line">      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))</div><div class="line">    tf.summary.scalar(<span class="string">'stddev'</span>, stddev)</div><div class="line">    tf.summary.scalar(<span class="string">'max'</span>, tf.reduce_max(var))</div><div class="line">    tf.summary.scalar(<span class="string">'min'</span>, tf.reduce_min(var))</div><div class="line">    tf.summary.histogram(<span class="string">'histogram'</span>, var)</div></pre></td></tr></table></figure></p>
<p>而对于单个<code>Variable</code>，可以用<code>tf.summary.scalar(name,variable)</code>的形式进行收集。</p>
<h4 id="3-Merge-summary-data"><a href="#3-Merge-summary-data" class="headerlink" title="3. Merge summary data"></a>3. Merge summary data</h4><p>定义好要收集的信息，需要对他们进行汇总，此时用<code>tf.summary.merge_all</code>进行汇总，例如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">merged = tf.summary.merge_all()</div></pre></td></tr></table></figure></p>
<h4 id="4-FileWriter-for-saving-the-log"><a href="#4-FileWriter-for-saving-the-log" class="headerlink" title="4. FileWriter for saving the log"></a>4. FileWriter for saving the log</h4><p>为了将训练中收集的数据保存到日志中，可以用<code>tf.summary.FileWriter</code>来实现，此时需要提供存放日志的文件夹位置，即<code>logdir</code>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">logdir = <span class="string">'./log'</span></div><div class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(logdir):</div><div class="line">    os.mkdir(logdir)</div><div class="line">train_writer = tf.summary.FileWriter(logdir + <span class="string">'/train'</span>,</div><div class="line">                                      sess.graph)</div><div class="line">test_writer = tf.summary.FileWriter(logdir + <span class="string">'/test'</span>)</div></pre></td></tr></table></figure></p>
<p>此时，利用<code>sess.run(tf.global_variables_initializer())</code>初始化所有Tensor和Variable,便可以开始训练网络。</p>
<h4 id="5-Running"><a href="#5-Running" class="headerlink" title="5. Running"></a>5. Running</h4><p><code>merged</code>的类型为<code>tensorflow.python.framework.ops.Tensor</code>，属于tf.Graph的一部分。因此也需要在<code>session</code>中运行，并且要提供<code>feed_dict</code>。相应的python实现如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">summary, _ = sess.run(</div><div class="line">                [merged, train_step], </div><div class="line">                feed_dict=feed_dict)</div><div class="line">train_writer.add_summary(summary)</div></pre></td></tr></table></figure></p>
<h4 id="6-利用TensorBoard可视化"><a href="#6-利用TensorBoard可视化" class="headerlink" title="6. 利用TensorBoard可视化"></a>6. 利用TensorBoard可视化</h4><p>TensorFlow提供了<code>tensorboard.py</code>脚本用于可视化。利用如下指令启动并运行TensorBoard, 其默认端口为6006，这里利用<code>--port</code>显式表达</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ tensorboard --logdir=<span class="string">'./log --port=6006'</span></div></pre></td></tr></table></figure>
<p>注：在执行此条指令的时候，可能会报错<em>command not found: tensorboard</em>，解决方法参考<a href="http://blog.csdn.net/uestc_c2_403/article/details/73457368" target="_blank" rel="external">本文</a></p>
<p>以下给出运行的样例，我写了一个<a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook-tensorboard-mlp.ipynb" target="_blank" rel="external">notebook</a>，欢迎来PR :)</p>
<ul>
<li>Graph及FC1和train节点</li>
</ul>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180124/fig_graph.png?raw=true" height="360" width="450">
</center>

<ul>
<li>Scalars and histograms</li>
</ul>
<center>
<img src="https://github.com/myinxd/canal-images/blob/master/images/blog-180124/fig_scalars.png?raw=true" height="450" width="800">
</center>


<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://www.amazon.cn/dp/B06WGP12TV/" target="_blank" rel="external">TensorFlow实战Google深度学习框架</a><br>[2] <a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter" target="_blank" rel="external">tf.summary.FileWriter</a><br>[3] <a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard" target="_blank" rel="external">TensorBoard: Visualizing Learning</a><br>[3] <a href="http://blog.csdn.net/uestc_c2_403/article/details/73457368" target="_blank" rel="external">tensorboard在linux下的启动问题</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/01/24/tensorflow-graph-and-tensorboard/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="/all-archives/2018/page/2/">
              <span>OLDER POSTS</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
        <li class="pagination-number">page 1 of 3</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2018 Jason Ma. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-remove"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Jason Ma</h4>
        
            <div id="about-card-bio"><p>We are in the same story.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Astronomer? Software engineer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker"></i>
                <br/>
                Shanghai
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/script-peofhqjkzcghmndknakluequy1y6owxdwpaqyju9ntl9zxnk7rdolb3rjjoj.min.js"></script>
<!--SCRIPTS END--><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



    </body>
</html>
