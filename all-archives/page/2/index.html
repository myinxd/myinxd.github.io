
<!DOCTYPE html>
<html lang="en">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Jason&#39;s blog">
    <title>Archives - Jason&#39;s blog</title>
    <meta name="author" content="Jason Ma">
    
    
    
        <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <meta name="description" content="Valar morghulis, valar dohaeris.">
<meta property="og:type" content="blog">
<meta property="og:title" content="Jason&#39;s blog">
<meta property="og:url" content="http://www.mazhixian.me/all-archives/page/2/index.html">
<meta property="og:site_name" content="Jason&#39;s blog">
<meta property="og:description" content="Valar morghulis, valar dohaeris.">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jason&#39;s blog">
<meta name="twitter:description" content="Valar morghulis, valar dohaeris.">
    
    
        
    
    
        <meta property="og:image" content="http://www.mazhixian.me/assets/images/profile.jpg"/>
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/style-pz4cc6y13wt2trzqa8l3n9v0yykr0sstdaheem7qj628nhjmhp9pfawvqawz.min.css">
    <!--STYLES END-->
    
    <script type="text/javascript">
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-112822605-1', 'auto');
        ga('send', 'pageview');
    </script>


    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?20f3bcc8683b066ff79f4e36134e3982";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="1">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/ ">Jason&#39;s blog</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="1">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="/#about">
                    <img class="sidebar-profile-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Jason Ma</h4>
                
                    <h5 class="sidebar-profile-bio"><p>We are in the same story.</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/ "
                            
                            title="Home"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-categories"
                            
                            title="Categories"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="Tags"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-archives"
                            
                            title="Archives"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="Search"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="About"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/myinxd" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fa fa-lg fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto:zx@mazhixian.me" target="_blank" rel="noopener" title="Mail">
                    
                        <i class="sidebar-button-icon fa fa-lg fa-envelope-o" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/404.html"
                            
                            title="Naive"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-hourglass-start" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Naive</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="RSS"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="1"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/26/range-based-for-loop-by-cpp/">
                            Range based for loop by cpp
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-26T22:03:19+08:00">
	
		    Mar 26, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>最近落了好多没写了，感觉已经废了。继续C++的笔记，关于<em>range-based for loop</em>的使用，一个C++11的标准。首先我会给出样例，然后针对gcc的报错，说明Ubuntu16.04-LTS下gcc的更新方法。</p>
<h4 id="range-based-for-loop"><a href="#range-based-for-loop" class="headerlink" title="range-based for loop"></a>range-based for loop</h4><p>C++11标准中增加了一种新的for循环的方式，称为range-based for loop，即基于范围的for循环，这个类似于python中直接进行列表索引的for循环。请看下面的样例，分别是C++和python的for循环写法，</p>
<h5 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line"><span class="function"></span>&#123;</div><div class="line">    <span class="keyword">int</span> numArray[<span class="number">5</span>] = &#123;<span class="number">0</span>, <span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>&#125;;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> num : numArray)</div><div class="line">	    <span class="built_in">cout</span> &lt;&lt; num &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="python"><a href="#python" class="headerlink" title="python"></a>python</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">numArray = [<span class="number">0</span>, <span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>]</div><div class="line"></div><div class="line"><span class="keyword">for</span> num <span class="keyword">in</span> numArray:</div><div class="line">    print(num)</div></pre></td></tr></table></figure>
<p>二者的输出结果均为如下形式，<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">0</div><div class="line">11</div><div class="line">22</div><div class="line">33</div><div class="line">44</div></pre></td></tr></table></figure></p>
<p>显然，相对于C99的for循环，基于范围的这种for循环能够减少多行代码量。</p>
<h4 id="g-update"><a href="#g-update" class="headerlink" title="g++ update"></a>g++ update</h4><p>为了应用C++11/14的新标准，<code>gcc/g++</code>也需要做相应的更新，由于我还在Ubuntu-16.04 LTS的坑里，gcc的最高版本为5.4。如果编译时看到如下的警告，则需要对gcc进行更新。<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">warning: range-based ‘<span class="keyword">for</span>’ loops only available with -std=c++11 or -std=gnu++11</div></pre></td></tr></table></figure></p>
<p>更新方法如下，<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo add-apt-repository ppa:ubuntu-toolchain-r/<span class="built_in">test</span></div><div class="line">sudo apt update</div><div class="line">sudo apt install gcc-7 g++-7</div></pre></td></tr></table></figure></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a href="https://www.linuxidc.com/Linux/2016-11/136840.htm" target="_blank" rel="external">Ubuntu升级GCC版本</a></li>
<li>Sams Teach Yourself C++ in One Hour a Day</li>
</ul>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/26/range-based-for-loop-by-cpp/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/25/configure-permalinks-in-wordpress-with-nginx-and-avoid-404/">
                            Configure permalinks in wordpress with nginx and avoid 404
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-25T15:18:36+08:00">
	
		    Mar 25, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>简单记录一下wordpress配置静态链接后，页面无法重定向，网页404的解决方法。可参考的posts特别多，我罗列了一些在references里。我会从三个方面来说这个问题，(1) wordpress静态链接的配置； (2) 导致404的原因及解决方法； (3) 自定义链接插件</p>
<h4 id="wordpress静态链接的配置"><a href="#wordpress静态链接的配置" class="headerlink" title="wordpress静态链接的配置"></a>wordpress静态链接的配置</h4><p>Wordpress可供配置的静态链接很多</p>
<h4 id="自定义链接插件"><a href="#自定义链接插件" class="headerlink" title="自定义链接插件"></a>自定义链接插件</h4><p>custom permalinks plugin</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ol>
<li><a href="https://blog.csdn.net/hanshileiai/article/details/45580457" target="_blank" rel="external">ubuntu 下 wordpress 设置 Permalink 为 自定义结构后出现404页面 nginx - 404 not found page for permalinks</a></li>
<li><a href="https://wordpress.org/plugins/custom-permalinks/" target="_blank" rel="external">Custom Permalinks plugin</a></li>
<li><a href="http://www.mazhixian.me/2018/01/23/multiple-websites-with-nginx/">multiple websites with nginx</a></li>
</ol>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/25/configure-permalinks-in-wordpress-with-nginx-and-avoid-404/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/17/confusion-matrix-and-generation-with-tensorflow/">
                            Confusion matrix and generation with TensorFlow
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-17T14:45:29+08:00">
	
		    Mar 17, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>简单记录一下多分类问题中的一种评价方法及其可视化，混淆矩阵 (confusion matrix, CM)。首先给出其定义及作用，然后给出样例。</p>
<h4 id="Confusion-matrix"><a href="#Confusion-matrix" class="headerlink" title="Confusion matrix"></a>Confusion matrix</h4><p>混淆矩阵通过比较分类器的<strong>预测</strong>和<strong>真实</strong>标签，评估分类器效果，通常用于多分类问题。TF的<a href="https://www.tensorflow.org/tutorials/audio_recognition" target="_blank" rel="external">audio recognition tutorial</a>里对混淆矩阵的评价是, <em>This matrix can be more useful than just a single accuracy score because it gives a good summary of what mistakes the network is making.</em> 即混淆矩阵可以帮助分析分类器在哪些类上的表现最差。相对于单一的准确率这种衡量指标，更加直观。</p>
<p>混淆矩阵是一个二维的方阵，横轴代表真实标签，枞轴代表预测标签，其中的元素<script type="math/tex">CM_{ij}</script>代表实际为第<script type="math/tex">i</script>，被分成第<script type="math/tex">j</script>类的样本数目。<strong>显然矩阵的非零元素集中在对角线时，分类器的表现更优异。</strong></p>
<h4 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h4><p>下面给出一个样例，这是一个六分类的问题，结果来自我们近期的工作。其中A的样本量约1000, B的样本量约10000，A random是随机产生预测标签的CM矩阵。如下所示，A的CM map中，多数样本集中在对角线；B的表现也不错，但(6,6)的色块显然淡了很多，说明分类器对第六类的分类效果不好；而A random，因为是随机生成的，其CM的各个元素的样本数比较均衡，因此分类准确率也非常差。</p>
<center>
<img src="https://github.com/myinxd/canal-notebooks/blob/master/images/fig-confmat.png?raw=true" height="200" width="720">
</center>

<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://www.tensorflow.org/tutorials/audio_recognition" target="_blank" rel="external">Simple Audio Recognition</a><br>[2] <a href="https://www.tensorflow.org/api_docs/python/tf/confusion_matrix" target="_blank" rel="external">tf.confusion_matrix</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/17/confusion-matrix-and-generation-with-tensorflow/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/17/install-macOS-10-12-with-virtualbox/">
                            Install macOS 10.9 with virtualbox-5.1 on Unbuntu 1710
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-17T14:07:15+08:00">
	
		    Mar 17, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>首先，建议不要作死，还是去买mac吧，太折腾人了！！然后进入正题，如何在Ubuntu 17.10上利用virtualbox 5.1安装MacOS 10.9虚拟机。涉及CPUID问题、vdmk转vdi，vdi的resize，以及EFI的问题。好几点都不太懂，慢慢摸索吧。 </p>
<p>再吐个槽，不要随意自己更新virtualbox，因为如果是UEFI安装的ubuntu，是没法将Virtualbox的modprov部署进系统image的，然后virtualbox就彻底挂了。。。解决方法是升级系统或者重装。</p>
<h4 id="镜像去哪里找"><a href="#镜像去哪里找" class="headerlink" title="镜像去哪里找"></a>镜像去哪里找</h4><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>具体的配置参考文献里有很多，我就不赘述了。。。这里主要说明一下CPUID的问题。。。我的CPU是i3 7100，按道理说其架构不适合装黑苹果，不过可以通过修改虚拟机的cpuid来解决这个问题。。。网上的方法太坑爹了，固定了cpuid，其实这个要自己去查的，每一代intel架构不太一样。查询方法如下，<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">VBoxManage list hostcpuids</div><div class="line"><span class="comment"># It will print</span></div><div class="line">Host CPUIDs:</div><div class="line"></div><div class="line">Leaf no.  EAX      EBX      ECX      EDX</div><div class="line">00000000  00000016 756e6547 6c65746e 49656e69</div><div class="line">00000001  000906e9 00100800 7ffafbbf bfebfbff</div><div class="line">00000002  76036301 00f0b5ff 00000000 00c30000</div><div class="line">00000003  00000000 00000000 00000000 00000000</div><div class="line">00000004  1c004121 01c0003f 0000003f 00000000</div><div class="line"><span class="comment"># 找到00000001这一行，</span></div><div class="line">替换到xxx.vbox中</div></pre></td></tr></table></figure></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">VBoxManage modifyvm <span class="string">"macOS"</span> --cpuidset 00000001 000306a9 00100800 3d9ae3bf bfebfbff</div><div class="line">VBoxManage setextradata <span class="string">"macOS"</span> <span class="string">"VBoxInternal/Devices/efi/0/Config/DmiSystemProduct"</span> <span class="string">"iMac11,3"</span></div><div class="line">VBoxManage setextradata <span class="string">"macOS"</span> <span class="string">"VBoxInternal/Devices/efi/0/Config/DmiSystemVersion"</span> <span class="string">"1.0"</span></div><div class="line">VBoxManage setextradata <span class="string">"macOS"</span> <span class="string">"VBoxInternal/Devices/efi/0/Config/DmiBoardProduct"</span> <span class="string">"Iloveapple"</span></div><div class="line">VBoxManage setextradata <span class="string">"macOS"</span> <span class="string">"VBoxInternal/Devices/smc/0/Config/DeviceKey"</span> <span class="string">"ourhardworkbythesewordsguardedpleasedontsteal(c)AppleComputerInc"</span></div><div class="line">VBoxManage setextradata <span class="string">"macOS"</span> <span class="string">"VBoxInternal/Devices/smc/0/Config/GetKeyFromRealSMC"</span> 1</div></pre></td></tr></table></figure>
<p>更新以后如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;ExtraDataItem name=&quot;VBoxInternal/Devices/efi/0/Config/DmiBoardProduct&quot; value=&quot;Iloveapple&quot;/&gt;</div><div class="line">&lt;ExtraDataItem name=&quot;VBoxInternal/Devices/efi/0/Config/DmiSystemProduct&quot; value=&quot;iMac11,3&quot;/&gt;</div><div class="line">&lt;ExtraDataItem name=&quot;VBoxInternal/Devices/efi/0/Config/DmiSystemVersion&quot; value=&quot;1.0&quot;/&gt;</div><div class="line">&lt;ExtraDataItem name=&quot;VBoxInternal/Devices/smc/0/Config/DeviceKey&quot; value=&quot;ourhardworkbythesewordsguardedpleasedontsteal(c)AppleComputerInc&quot;/&gt;</div><div class="line">&lt;ExtraDataItem name=&quot;VBoxInternal/Devices/smc/0/Config/GetKeyFromRealSMC&quot; value=&quot;1&quot;/&gt;</div><div class="line"></div><div class="line">&lt;CPU&gt;</div><div class="line">    &lt;PAE enabled=&quot;true&quot;/&gt;</div><div class="line">    &lt;LongMode enabled=&quot;true&quot;/&gt;</div><div class="line">    &lt;HardwareVirtExLargePages enabled=&quot;false&quot;/&gt;</div><div class="line">    &lt;CpuIdTree&gt;</div><div class="line">    &lt;CpuIdLeaf id=&quot;1&quot; eax=&quot;591593&quot; ebx=&quot;34605056&quot; ecx=&quot;2147154879&quot; edx=&quot;3219913727&quot;/&gt;</div><div class="line">    &lt;/CpuIdTree&gt;</div><div class="line">&lt;/CPU&gt;</div></pre></td></tr></table></figure></p>
<h3 id="resize"><a href="#resize" class="headerlink" title="resize"></a>resize</h3><p>VBoxManage clonehd “MavericksInstaller.vmdk” “MavericksInstaller.vdi” —format vdi<br>VBoxManage list hdds<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">UUID:           501b0eed-167e-4b38-96ff-93efa707b5fc</div><div class="line">Parent UUID:    base</div><div class="line">State:          created</div><div class="line">Type:           normal (base)</div><div class="line">Location:       xxx/macOS/MavericksInstaller.vdi</div><div class="line">Storage format: vdi</div><div class="line">Capacity:       10240 MBytes</div><div class="line">Encryption:     disabled</div></pre></td></tr></table></figure></p>
<p>VBoxManage modifyhd 501b0eed-167e-4b38-96ff-93efa707b5fc —resize 40960<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">UUID:           501b0eed-167e-4b38-96ff-93efa707b5fc</div><div class="line">Parent UUID:    base</div><div class="line">State:          created</div><div class="line">Type:           normal (base)</div><div class="line">Location:       xxx/macOS/MavericksInstaller.vdi</div><div class="line">Storage format: vdi</div><div class="line">Capacity:       40960 MBytes</div><div class="line">Encryption:     disabled</div></pre></td></tr></table></figure></p>
<h3 id="解决mediakit-报告设备上的空间不足以执行"><a href="#解决mediakit-报告设备上的空间不足以执行" class="headerlink" title="解决mediakit 报告设备上的空间不足以执行"></a>解决mediakit 报告设备上的空间不足以执行</h3><p>最简单粗暴的方法，重新挂载一个vdi，利用磁盘工具，抹掉，然后就行了。。。</p>
<h3 id="分辨率调整"><a href="#分辨率调整" class="headerlink" title="分辨率调整"></a>分辨率调整</h3><p>VBoxManage setextradata “macOS” VBoxInternal2/EfiGopMode 3</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul>
<li><a href="https://www.cnblogs.com/liming2017/p/7566953.html" target="_blank" rel="external">https://www.cnblogs.com/liming2017/p/7566953.html</a></li>
<li><a href="https://jingyan.baidu.com/article/1876c85274dcca890a13767a.html" target="_blank" rel="external">https://jingyan.baidu.com/article/1876c85274dcca890a13767a.html</a></li>
<li><a href="https://techsviewer.com/install-macos-sierra-virtualbox-windows/" target="_blank" rel="external">https://techsviewer.com/install-macos-sierra-virtualbox-windows/</a></li>
<li><a href="https://www.youtube.com/watch?v=pVc6rxk3OUM" target="_blank" rel="external">https://www.youtube.com/watch?v=pVc6rxk3OUM</a></li>
<li><a href="https://www.virtualbox.org/wiki/Download_Old_Builds_5_0" target="_blank" rel="external">https://www.virtualbox.org/wiki/Download_Old_Builds_5_0</a></li>
<li><a href="https://forums.virtualbox.org/viewtopic.php?f=6&amp;t=53880" target="_blank" rel="external">https://forums.virtualbox.org/viewtopic.php?f=6&amp;t=53880</a></li>
<li><a href="https://www.cnblogs.com/platero/p/4105808.html" target="_blank" rel="external">https://www.cnblogs.com/platero/p/4105808.html</a></li>
<li><a href="https://stackoverflow.com/questions/12349757/change-macos-x-guest-screen-resolution-for-virtualbox" target="_blank" rel="external">https://stackoverflow.com/questions/12349757/change-macos-x-guest-screen-resolution-for-virtualbox</a></li>
</ul>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/17/install-macOS-10-12-with-virtualbox/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/17/simple-speech-recognition-example-by-tensorflow/">
                            A simple audio recognition example by tensorflow
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-17T11:17:02+08:00">
	
		    Mar 17, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    
                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/17/simple-speech-recognition-example-by-tensorflow/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/15/recurrent-neural-network-and-lstm/">
                            Recurrent neural network and LSTM
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-15T09:56:04+08:00">
	
		    Mar 15, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>简单记录一下循环神经网络 (recurrent neural network, RNN)， 另一种RNN，主要关注时间序列的预测、分类和识别等问题。这里卖个瓜，前面有讨论过残差神经网络，感兴趣地可以去围观，链接见文末。<br>本文首先讨论RNN的motivation及其特点；然后是为了解决长程依赖 (long-term dependencies) 而提出的long short term memory (LSTM) 结构； 最后是二者在tensorflow中的简单样例。参考文献很多，这里强烈案例下面两篇文章！</p>
<ul>
<li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">Understanding LSTM</a></li>
<li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">The Unreasonable Effectiveness of Recurrent Neural Networks</a></li>
</ul>
<h4 id="Recurrent-neural-network"><a href="#Recurrent-neural-network" class="headerlink" title="Recurrent neural network"></a>Recurrent neural network</h4><p>循环神经网络的动机是<em>刻画一个时间序列当前输入与此前信息的联系</em>，从网络结构上，循环神经网络通过称为<strong>循环体</strong>的模块 (如下图) 实现对信息的记忆，即该层在<script type="math/tex">t-1</script>时刻的输出状态<script type="math/tex">\mathbf{h_{t-1}}</script>会被记录，并作为<script type="math/tex">t</script>时刻该模块输入的一部分，以级联的形式与<script type="math/tex">\mathbf{x_t}</script>构成此刻的输入 <script type="math/tex">[\mathbf{h_{t-1}}, \mathbf{x_{t}}]</script>.</p>
<p>显然，循环体中的循环理论上是无穷的，但在实际应用中会限制循环的次数以避免<strong>梯度消失 (gradient vanishing) </strong>的问题，用<code>num_step</code>来定义，即循环体的基本模块被复制并展开为<code>num_step</code>个。如<br>文献[4]所述，循环体结构是RNN的基础，在RNN中对于复制展开的循环体，其参数是共享的。这一点与卷积神经网络中的权值共享有类似之处。在<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">这篇</a>文章里给出了非常多的RNN的应用场景，我很喜欢里面关于手写体识别的问题，体现了权值共享的效果。</p>
<center>
<img src="https://github.com/myinxd/canal-notebooks/blob/master/images/fig-rnn.png?raw=true" height="140" width="500">
</center>

<p>设<script type="math/tex">t</script>时刻循环体的输入为<script type="math/tex">\mathbf{x}(t)</script>，$t-1$时刻循环体的输出状态为<script type="math/tex">\mathbf{h(t)}</script>，则RNN中<script type="math/tex">t</script>时刻的输出<script type="math/tex">\mathbf{h}(t)</script>为，</p>
<script type="math/tex; mode=display">
\begin{equation}
\mathbf{h}(t) = \rm{tanh}\left(W\cdot[\mathbf{h}(t-1),\mathbf{x}(t)] + b\right).
\end{equation}</script><p>其中<script type="math/tex">W</script>是权值矩阵，其shape为<script type="math/tex">[\mathrm{len}(\mathbf{h}) + \mathrm{len}(\mathbf{x}), \mathrm{len}(\mathbf{h})]</script>, <script type="math/tex">b</script>为偏置。这里采用的激活函数是tanh，将数据限制到<script type="math/tex">[-1,1]</script>之间。</p>
<p>那么，为什么用tanh，而不是有high reputation的ReLU? 知乎的<a href="https://www.zhihu.com/question/61265076/answer/186644426" target="_blank" rel="external">这个讨论</a>给出了很棒的解释，参考Hinton<a href="https://arxiv.org/abs/1504.00941" target="_blank" rel="external">论文</a>中的观点 <em>ReLUs seem inappropriate for RNNs because they can have very large outputs so they might be expected to be far more likely to explode than units thathave bounded values.</em> ReLU将输出的值限制在<script type="math/tex">[0, \infty)</script>之间，而RNN中循环体之间的权值是共享的，经过公式(1)的多次作用，相当于对<script type="math/tex">W</script>做了连乘，ReLU函数会导致梯度爆炸的问题。因此，采用tanh可以将每层的输出空控制在限定的范围内，既避免了梯度消失，也避免了梯度爆炸的问题。</p>
<h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><p>在时间序列的预测中存在长期依赖 (long-term dependencies) 的问题，即网络需要记住离时间<script type="math/tex">t</script>很远的某个时刻的信息，固定的<code>num_step</code>将不适用于这一情形，并且长时间间隔下的梯度消失问题将无法处理。因此，需要对RNN的循环体模块进行修改，即长短时记忆网络 (long short term memory, LSTM). </p>
<p>LSTM的基本模块如下图所示，参考<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">Understanding LSTM</a>的解释，<em>The key to LSTMs is the cell state, the horizontal line running through the top of the diagram. The cell state is kind of like a conveyor belt.</em> 即LSTM的核心是组成为<code>cell state</code>，用于存储和记忆上文的信息，类似传送带的功能。</p>
<p>而<code>cell state</code>的更新，通过三个逻辑门以及<script type="math/tex">\mathbf{x_t}</script>和<script type="math/tex">\mathbf{h_{t-1}}</script>共同完成。它们分别称为 (1) forget gate, (2) input gate, (3) output gate. 采用sigmoid函数将数值规范化到<script type="math/tex">[0,1]</script>区间，并与待处理信号进行点乘，本质上实现软判决.</p>
<center>
<img src="https://github.com/myinxd/canal-notebooks/blob/master/images/fig-lstm.png?raw=true" height="400" width="640">
</center>

<p>与RNN类似，首先将<script type="math/tex">t-1</script>时刻LSTM cell的输出<script type="math/tex">\mathbf{h}_{t-1}</script>与<script type="math/tex">t</script>时刻的输入<script type="math/tex">\mathbf{x}_{t}</script>进行级联，逐一通过三个门，</p>
<ul>
<li>遗忘门 (Forget gate)<script type="math/tex; mode=display">
\begin{equation}
  \mathbf{f_t} = \sigma\left(W_f \cdot [\mathbf{h_{t-1}}, \mathbf{x_{t}}] + b_f\right) 
\end{equation}</script></li>
<li>输入门 (Input gate)<script type="math/tex; mode=display">
\begin{equation}
\mathbf{i_t} = \sigma\left(W_i \cdot [\mathbf{h_{t-1}}, \mathbf{x_{t}}] + b_i \right).
\end{equation}</script></li>
<li>输出门 (Output gate)<script type="math/tex; mode=display">
\begin{equation}
\mathbf{o_t} = \sigma\left(W_o \cdot [\mathbf{h_{t-1}}, \mathbf{x_{t}}] + b_o \right).
\end{equation}</script></li>
</ul>
<p>其中遗忘门的作用是<strong>抛弃cell state中不需要的信息</strong>，与<script type="math/tex">\mathbf{C_{t-1}}</script>作用； 输入门则是<strong>决定cell state中待更新的信息</strong>，与<script type="math/tex">\mathbf{\tilde{C}_t}</script>，即state candidates作用；输出门则从更新后的<code>cell state</code>中<strong>决定输出的状态</strong>。结合以上三个门结构，便可以更新<code>cell state</code>以及<code>cell output</code>,</p>
<ul>
<li>cell state update<script type="math/tex; mode=display">
\begin{align}
\mathbf{\tilde{C_{t}}} &= \rm{tanh}\left(W_c \cdot [\mathbf{h_{t-1}}, \mathbf{x_{t}}] + b_c \right) \\ 
\mathbf{C_t} &= \mathbf{f_t}\cdot\mathbf{C_{t-1}} + \mathbf{i_t} \cdot \mathbf{\tilde{C_{t}}}
\end{align}</script></li>
<li>cell output upadte<script type="math/tex; mode=display">
\begin{equation}
\mathbf{h_{t}} = \rm{tanh}(\mathbf{C_{t}}) \cdot \mathbf{o_t}
\end{equation}</script></li>
</ul>
<h4 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h4><p>参考《TensorFlow实战》第7章的LSTM基于<a href="http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz" target="_blank" rel="external">PTB数据集</a>的语言预测样例，以及TensorFlow的<a href="https://www.tensorflow.org/tutorials/recurrent" target="_blank" rel="external">Tutorial</a>，设计了一个小实验，对比RNN和LSTM的performance，以及激活函数对于RNN的影响。(详细的notebooks见这里: <a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook-rnn-tanh.ipynb" target="_blank" rel="external">RNN</a>, <a href="https://github.com/myinxd/canal-notebooks/blob/master/deeplearning/notebook-lstm.ipynb" target="_blank" rel="external">LSTM</a>)</p>
<p>这里给出<code>tf.contrib.rnn</code>中提供的用于搭建RNN和LSTM cell的类的实例化方法，以及如何构建多个Recurrent层，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line"><span class="comment"># RNN</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_cell</span><span class="params">(num_units, activation, reuse=None)</span>:</span></div><div class="line">   <span class="keyword">return</span> tf.contrib.rnn.BasicLSTMCell(</div><div class="line">       num_units=num_units,  </div><div class="line">       activation=activation,</div><div class="line">       reuse=reuse)</div><div class="line"></div><div class="line"><span class="comment"># LSTM</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_cell</span><span class="params">(num_units, forget_bias=<span class="number">0.0</span>, state_in_tuple=True, reuse=None)</span>:</span></div><div class="line">	<span class="keyword">return</span> tf.contrib.rnn.BasicLSTMCell(</div><div class="line">    	num_units=size, </div><div class="line">        forget_bias=forget_bias, </div><div class="line">        state_is_tuple=state_in_tuple,</div><div class="line">        reuse=reuse)</div><div class="line"></div><div class="line"><span class="comment"># Multiple layers</span></div><div class="line">attn_cell = rnn_cell</div><div class="line">numlayers = <span class="number">2</span></div><div class="line">cell = tf.contrib.rnn.MultiRNNCell(</div><div class="line">	[attn_cell() <span class="keyword">for</span> _ <span class="keyword">in</span> range(numlayers)],</div><div class="line">    state_is_tuple=<span class="keyword">True</span>)</div></pre></td></tr></table></figure></p>
<p>另外，在PTB的TF教程里，设置了可变的学习率以及梯度的clipping用于抑制梯度爆炸 (gradient explosion) 的问题，代码如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Adjustable learning rate</span></div><div class="line">new_lr = tf.placeholder(tf.float32, shape=[], name=<span class="string">"new_learning_rate"</span>)</div><div class="line">lr_update = tf.assign(self._lr, self._new_lr) <span class="comment"># use tf.assign to transfer the updated lr</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">assign_lr</span><span class="params">(session, lr_value)</span>:</span></div><div class="line">	sess.run(self._lr_update, feed_dict=&#123;new_lr: lr_value&#125;)</div><div class="line"></div><div class="line"><span class="comment"># Gradient clipping</span></div><div class="line">...</div><div class="line">max_grad_norm = <span class="number">5.0</span> <span class="comment"># maximum gradient</span></div><div class="line">tvars = tf.trainable_variables()  <span class="comment"># Get all trainable variables</span></div><div class="line">grads, _ = tf.clip_by_global_norm(</div><div class="line">	tf.gradients(cost, tvars), max_grad_norm)</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(self._lr)</div><div class="line">train_op = optimizer.apply_gradients(</div><div class="line">    zip(grads, tvars),</div><div class="line">    global_step = tf.contrib.framework.get_or_create_global_step())</div></pre></td></tr></table></figure></p>
<p>下面来比较一下RNN和LSTM的效果。比较的指标是perplexity (复杂度)，用于刻画该模型能够估计出某一句话的概率，其数值越小，模型表现越好。</p>
<center>
<img src="https://github.com/myinxd/canal-notebooks/blob/master/images/fig-rnn-lstm-cmp.png?raw=true" height="300" width="500">
</center>

<p>容易看出，LSTM的表现是优于RNN的。除此之外，采用tanh函数的RNN要显著好于采用ReLU，在训练中也出现了<em>RuntimeWarning: overflow encountered in exp</em>的警告，说明出现了gradient explosion的问题。最后，我尝试增加了RNN的层数，但是效果并没有变好，也许是参数多了？也有可能是我偷懒了，没多训测试几次。。。</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">Understanding LSTM</a><br>[2] <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">The Unreasonable Effectiveness of Recurrent Neural Networks</a><br>[3] <a href="https://www.tensorflow.org/tutorials/recurrent" target="_blank" rel="external">Tensorflow tutorial</a><br>[4] TensorFlow实战Google深度学习框架<br>[5] TensorFlow实战<br>[6] <a href="https://www.zhihu.com/question/61265076/answer/186644426" target="_blank" rel="external">RNN中为什么要采用tanh而不是ReLu作为激活函数？</a></p>
<h3 id="广告位"><a href="#广告位" class="headerlink" title="广告位"></a>广告位</h3><p><a href="http://www.mazhixian.me/2018/01/21/resnet-with-tensorflow/">Residual network I — block and bottleneck</a><br><a href="http://www.mazhixian.me/2018/01/27/resnet-with-tensorflow-2/">Residual network II — realize with tensorflow</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/15/recurrent-neural-network-and-lstm/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/13/expectation-maximization-algorithm/">
                            Expectation maximization algorithm
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-13T15:16:35+08:00">
	
		    Mar 13, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>回顾一下GMM以及HMM等模型的求解方法，即著名的Expectation Maximization (EM) 算法。参考李航老师的《统计学习方法》，EM算法是一种迭代算法，用于含有隐含变量的概率模型参数的极大似然估计（MLE），或极大后验概率估计 (MPE).</p>
<h3 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h3><p>定义<script type="math/tex">Y</script>为观测随机变量，<script type="math/tex">Z</script>为隐含随机变量，则<script type="math/tex">Y</script>和<script type="math/tex">Z</script>一起构成完全数据 (complete-data)。假设待估计的概率模型参数为<script type="math/tex">\theta</script>，则观测数据的概率分布为<script type="math/tex">P(Y|\theta)</script>, 即为其似然函数，对应的对数似然函数为<script type="math/tex">L(\theta) = \log{P(Y|\theta)}</script>. 设<script type="math/tex">Y</script>和<script type="math/tex">Z</script>Z的联合概率分布为<script type="math/tex">P(Y,Z|\theta)</script>，那么完全数据的对数似然函数为<script type="math/tex">\log{P(Y,Z|\theta)}</script>.</p>
<p>EM算法的目的就是求解参数<script type="math/tex">\theta</script>，极大化观测量的对数似然函数<script type="math/tex">L(\theta)</script>。因为包含隐含量，所以采用迭代的方法，分为E (期望) 和M (极大化)两步，求解算法如下。</p>
<ol>
<li><p>初始化参数<script type="math/tex">\theta^{(0)}</script>;</p>
</li>
<li><p>E step: 记<script type="math/tex">\theta^{(i)}</script>为第<script type="math/tex">i</script>次迭代参数<script type="math/tex">\theta</script>的估计值，则第<script type="math/tex">i+1</script>次迭代，计算如下期望.</p>
<script type="math/tex; mode=display">
\begin{align}
Q(\theta,\theta^{(i)}) &= E_{z}[\log{P(Y,Z|\theta)}|Y,\theta^{(i)}] \notag \\
&=\sum_{z}{\log{P(Y,Z|\theta)P(Z|Y,\theta^{(i)})}},
\end{align}</script><p>其中<script type="math/tex">P(Z|Y,\theta^{(i)})</script>是在给定观测数据<script type="math/tex">Y</script>和当前估计的参数$\theta^{(i)}$下隐含变量<script type="math/tex">Z</script>的条件概率分布；<script type="math/tex">Q(\theta,\theta^{(i)})</script>定义为完全数据的对数似然函数在给定观测数据和当前参数下对隐含数据<script type="math/tex">Z</script>的条件概率分布<script type="math/tex">P(Z|Y,\theta^{(i)})</script>的期望，即<script type="math/tex">\log{P(Y|\theta)}</script>。</p>
</li>
<li><p>M step: 求使<script type="math/tex">Q(\theta, \theta^{(i)})</script>极大化的参数<script type="math/tex">\theta</script>，以确定第<script type="math/tex">i+1</script>次迭代的参数的估计值<script type="math/tex">\theta^{(i+1)}</script>, 即计算</p>
<script type="math/tex; mode=display">
\begin{align}
\theta^{(i+1)} = \mathrm{arg}\max\limits_{\theta}{Q(\theta,\theta^{(i)})}
\end{align}</script></li>
<li><p>重复E和M两步，直到收敛. </p>
</li>
</ol>
<p>李航老师也强调了一点：<strong>EM算法与初值的选择有关，选择不同的初值可能得到不同的参数估计值。</strong> 我在这个<a href="https://github.com/myinxd/canal-notebooks/blob/master/machinelearning/notebook-expectation-maximum-three-coiins.ipynb" target="_blank" rel="external">notebook</a>里给了一个样例，即“三硬币模型”。</p>
<h3 id="高斯混合模型的求解"><a href="#高斯混合模型的求解" class="headerlink" title="高斯混合模型的求解"></a>高斯混合模型的求解</h3><p>EM算法最经典的应用就是高斯混合模型的参数估计，该模型是语音信号处理的基础模型之一，其定义如下，</p>
<script type="math/tex; mode=display">
\begin{align}
P(\mathbf{y}|\mathbf{\theta}) = \sum_{k=1}^{K}{c_k\phi(\mathbf{y}|\mathbf{\theta_k)}}
\end{align}</script><p>其中，<script type="math/tex">c_k</script>是系数，<script type="math/tex">c_k\geq0</script>, <script type="math/tex">\sum_{k=1}^{K}{c_k=1}</script>; <script type="math/tex">\phi(\mathbf{y}|\mathbf{\theta_k})</script>是高斯分布，<script type="math/tex">\mathbf{\theta_k} = (\mathbf{\mu_k},\Sigma_k^2)</script>,</p>
<script type="math/tex; mode=display">
\begin{equation}
\phi(\mathbf{y}|\mathbf{\theta_k}) = \frac{1}{(2\pi)^{M/2}|\Sigma_k|}{-\exp{(\mathbf{y}-\mathbf{\mu_k})^{T}{\Sigma_{k}}^{-1}(\mathbf{y}-\mathbf{\mu_k})}}.
\end{equation}</script><p>在GMM模型中有，</p>
<ul>
<li>观测变量：<script type="math/tex">\mathbf{Y}</script>，</li>
<li>隐含变量：<script type="math/tex">\gamma_k\in{0,1}, k=1,~2,~,\cdots,~K</script>，表示<script type="math/tex">\mathbf{y}</script>是否来自第<script type="math/tex">k</script>个高斯分量</li>
<li>模型参数：<script type="math/tex">\mathbf{\theta} = {c_k, \mathbf{\theta_k}}, k=1,~2,~,\cdots,~K</script>.</li>
</ul>
<p>详细的推导见《统计学习方法》，这里给出GMM模型的E和M步骤.<br>设观测数据<script type="math/tex">\mathbf{Y} = \{\mathbf{y1},~\mathbf{y2},~\cdots,~\mathbf{y_N}\}</script></p>
<ul>
<li><p>E step</p>
<script type="math/tex; mode=display">
\begin{align}
\hat{\gamma_{jk}} = \frac{c_k\phi(\mathbf{y_j}|\mathbf{\theta_k})}{\sum_{k=1}^{K}{c_k\phi(\mathbf{y_j}|\mathbf{\theta_k})}} 
\end{align}</script><p>其中<script type="math/tex">j=1,~2,~\cdots,~,N, k=1,~2,~\cdots,~K</script>.</p>
</li>
<li><p>M step</p>
<script type="math/tex; mode=display">
\begin{align}
\hat{\mu}_{km} &= \sum_{j=1}^{N}{\hat{\gamma}_{jk}y_{jm}}/{\sum^{N}_{j=1}{\hat{\gamma}_{jk}}} 
\notag \\
\hat{\sigma}^{2}_{km} &= \sum_{j=1}^{N}{\hat{\gamma}_{jk}(y_{jm}-\mu_{km})^2}/{\sum_{j=1}^{N}{\hat{\gamma}_{jk}}} \notag \\
\hat{c}_{k} &= {\sum_{j=1}^{N}{\hat{\gamma}_{jk}}} / N
\end{align}</script><p>其中<script type="math/tex">m=1,~2,~\cdots,~,M, k=1,~2,~\cdots,~K</script>.</p>
</li>
</ul>
<p>最后，给出一个样例，简单的二维GMM，如下图，notebook见<a href="https://github.com/myinxd/canal-notebooks/blob/master/machinelearning/notebook-EM-GMM-2D.ipynb" target="_blank" rel="external">这里</a>.</p>
<center>
<img src="https://github.com/myinxd/canal-notebooks/blob/master/machinelearning/fig_gmm_2d.png?raw=true" height="600" width="600">
</center>

<p>可以看出，EM的估计效果还是不错的，并且提供初始化参数值的结果 (左下) 比随机初始化 (右下) 的结果要好。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] 李航，统计学系方法，2012 清华大学出版社<br>[2] <a href="https://stats.stackexchange.com/questions/70855/generating-random-variables-from-a-mixture-of-normal-distributions" target="_blank" rel="external">Generating random variables from a mixture of Normal distributions</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/13/expectation-maximization-algorithm/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/11/understanding-of-auc-curve/">
                            二分类及AUC的理解
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-11T13:36:59+08:00">
	
		    Mar 11, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>在机器学习中，二分类 (binary classification) 问题是最常出现且最经典的问题。本文首先解释二分类的样本标签问题，包括正例 (Positive)/反例 (Negative) 和真例 (True)/假例 (False) 这两组集合；紧接着介绍几种常用的分类器评估指标，例如精确度 (precision)、准确率 (accuracy)、敏感性 (sensitivity)、特异性 (specificity)等；最后，讨论对ROC曲线及其衍生的AUC指标的理解，并给出样例。</p>
<h4 id="二分类标签"><a href="#二分类标签" class="headerlink" title="二分类标签"></a>二分类标签</h4><p>应用于二分类的样本通常用正例 (Positive, P) 和反例 (Negative, N) 进行标注，作为实际标签。而经过分类器估计后的输出，根据其结果的正确与否，划分为真例 (True, T) 和假 (False, F)两个集合。因此，需要注意的是<code>T</code>和<code>F</code>两个集合均包含正例和反例样本。</p>
<p>根据实际标签和预测结果进行两两组合，得到四个子集，分别为真正率 (True positive, TP)、真反例 (True negative, TN)、假正率 (False positive, FP) 和假反例 (False negative, FN)，如下表所示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">预测正例</th>
<th style="text-align:center">预测反例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">实际正例</td>
<td style="text-align:center">TP</td>
<td style="text-align:center">FN</td>
</tr>
<tr>
<td style="text-align:center">实际反例</td>
<td style="text-align:center">FP</td>
<td style="text-align:center">TN</td>
</tr>
</tbody>
</table>
</div>
<p>通过对这四个子集样本的组合，可以得到一些评估指标，用于评价分类器的表现。这里我想强调一下对FN和FP的理解，其中FN指的是<em>实际为反例，但被分类器判断为正例</em>，而FP指的是<em>实际为正例，但被分类器判断为反例</em>，二者的合集为<code>F</code>。</p>
<h4 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h4><p>下面讨论常用的二分类器的评估指标 (index or measure)。定义<script type="math/tex">S</script>为所有的样本数量，<script type="math/tex">S_{P}</script>和<script type="math/tex">S_{N}</script>对应实际标注为正例和反例的样本数；<script type="math/tex">S_{T}</script>和<script type="math/tex">S_{F}</script>表示分类器估计的标签中正确和错误的样本数。相应的，定义<script type="math/tex">S_{\mathrm{TP}}</script>、<script type="math/tex">S_{\mathrm{TN}}</script>、<script type="math/tex">S_{\mathrm{FP}}</script>和<script type="math/tex">S_{\mathrm{FN}}</script>为TP、TN、FP、FN样本的数目。因此，定义如下的评估指标</p>
<ul>
<li><p>准确率 (accuracy)<br>准确率为分类器预测结果中判断正确的样本占所有样本的比例，即<script type="math/tex">\mathrm{acc} = S_{T}/S = (S_{\mathrm{TP}} + S_\mathrm{TN}) / S</script>.</p>
</li>
<li><p>精确度 (precision)<br>精确度又称为查准率，衡量分类器预测为正的样本中实际为正例的样本比例，即 <script type="math/tex">\mathrm{pre} = S_{\mathrm{TP}} / (S_{\mathrm{TP}} + S_{\mathrm{FP}})</script>.</p>
</li>
<li><p>敏感性 (sensitivity)<br>敏感性又称为召回率或真正率，衡量实际为正例的样本经过分类器预测后标记正确的样本所占比例，即<script type="math/tex">\mathrm{sen} = S_{\mathrm{TP}} / (S_{\mathrm{TP}} + S_{\mathrm{FN}})</script>.</p>
</li>
<li><p>F1-score<br>F1-score是对精确度和敏感性的结合，因为这两者本质上是矛盾的，通常敏感性越高则精确度会较低。F1-score的表达式为, <script type="math/tex">\mathrm{F1} = (2 \times \mathrm{pre} \times \mathrm{sen}) / (\mathrm{pre} + \mathrm{sen})</script>.</p>
</li>
<li><p>特异性 (specificity)<br>特异性是实际标注为反例的样本经过分类器预测正确的样本的比例，即<script type="math/tex">\mathrm{spe} = S_\mathrm{TN} / (S_\mathrm{FP} + S_\mathrm{TN})</script>.</p>
</li>
<li><p>假正率 (fasle positive rate)<br>假正率表示分类器预测为反例的样本中实际为反例的样本的比例，即<script type="math/tex">\mathrm{fpr} = S_\mathrm{TN} / (S_\mathrm{FN} + S_\mathrm{TN})</script>.</p>
</li>
</ul>
<p>对于这些评估指标，我的理解见下表，</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">评估指标</th>
<th style="text-align:center">意义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">准确率</td>
<td style="text-align:center">衡量了分类器总体上的准确性，不考虑样本的实际类别.</td>
</tr>
<tr>
<td style="text-align:center">精确度</td>
<td style="text-align:center">衡量了正例的分类准确性，通常比准确率要高.</td>
</tr>
<tr>
<td style="text-align:center">敏感性</td>
<td style="text-align:center">衡量了分类器对正例的泛化能力，在异常检测中应用较多.</td>
</tr>
<tr>
<td style="text-align:center">特异性</td>
<td style="text-align:center">衡量了分类器对反例的分类准确性.</td>
</tr>
<tr>
<td style="text-align:center">假正率</td>
<td style="text-align:center">与敏感性类似，衡量分类器对反例的泛化能力.</td>
</tr>
</tbody>
</table>
</div>
<h4 id="ROC和AUC"><a href="#ROC和AUC" class="headerlink" title="ROC和AUC"></a>ROC和AUC</h4><p>以上的评估指标均要求分类器的输出为确定的标签，而分类器通常输出的是样本被判断为正例的概率，为了得到标签，需要设定概率的门限，即大于该门限的概率对应的样本判断为正例，否则为反例。门限的设定，影响分类器的泛化能力。</p>
<p>因此，人们提出了receiver operating characteristic (ROC) 的概念，最早出现二战时检测敌机的雷达分析技术。在信号处理中，有这样一组指标，即捕获率 (catch rate) 和追踪率 (follow rate)，前者衡量了系统对于目标信号的捕获能力，后者衡量系统在捕获信号后继续追踪的能力。这两个指标，对应到二分类问题中就是敏感性或真正率 (truu positive rate, TPR)和假正率。</p>
<p>通过TPR和FRP即可求解ROC曲线。对分类器输出的样本概率进行排序，设定概率门限<code>thrs</code>，将高于该门限的样本判断为正例，反之判断为反例。而后，与实际的样本标签进行比较，计算对应该门限的TPR和FPR。记录不同门限处的TPR和FRP，则得到了该分类器的ROC曲线。</p>
<p>如下为ROC曲线的求解算法，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Step1. input labels and probs estimated by classifier;</div><div class="line">Step2. set thresholding step</div><div class="line">Step3. for thrs = 1.0 : step : 0.0</div><div class="line">		labels_est = zeros(size(labels))</div><div class="line">        labels_Est[probs &gt; thrs] = 1</div><div class="line">        calculate fpr and tpr w.r.t. thrs</div><div class="line">Step4. Draw the ROC curve</div></pre></td></tr></table></figure></p>
<p>针对不同的分类器，若某个分类器的ROC曲线整体在其他分类器的上方，则可认为该分类器最优。但往往存在ROC曲线交叉的情形，此时通过计算ROC曲线下方的面积，即AUC (area under curve)值来进行对比，AUC数值越大，分类器的分类效果越好，泛化能力越强。</p>
<p>给出一个ROC曲线和AUC的求解样例，具体的代码实现见<a href="https://github.com/myinxd/canal-notebooks/blob/master/machinelearning/notebook-roc-auc.ipynb" target="_blank" rel="external">这里</a>.</p>
<p>首先，设样本的标签和二分类器输出的概率为，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">labels = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]</div><div class="line">probs = [<span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.2</span>, <span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.3</span>, <span class="number">0.9</span>, <span class="number">0.5</span>]</div></pre></td></tr></table></figure></p>
<p>设定thrs的步长为0.1，则求解的TPR和FPR分别为，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">tpr = [<span class="number">0.0</span>, <span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]</div><div class="line">fpr = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.33</span>, <span class="number">0.33</span>, <span class="number">0.67</span>, <span class="number">0.83</span>, <span class="number">1.0</span>]</div></pre></td></tr></table></figure></p>
<p>最后，求解得到auc=0.967. 下图为该样例的ROC曲线，</p>
<center>
<img src="https://github.com/myinxd/canal-notebooks/blob/master/machinelearning/fig_roc.png?raw=true" height="250" width="360">
</center>

<p><a href="https://www.scikit-learn.org" target="_blank" rel="external">scikit-learn</a>也提供了求解auc的函数，其用法如下，<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line">fpr, tpr, thresholds = metrics.roc_curve(labels+<span class="number">1</span>, p, pos_label=<span class="number">2</span>)</div><div class="line">auc = metrics.auc(fpr, tpr)</div></pre></td></tr></table></figure></p>
<p>在我的notebook中，分别给出了我的实现和sklearn.metrics.auc的实现，二者结果相同。最后吐个槽，因为haroopad的bug，这篇是我重新写的！！！</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] 周志华，机器学习，2017 清华大学出版社<br>[2] <a href="https://www.zhihu.com/question/39840928" target="_blank" rel="external">机器学习和统计里面的auc怎么理解？</a><br>[3] <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html" target="_blank" rel="external">sklearn.metrics.auc</a></p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/11/understanding-of-auc-curve/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/06/svm-hyperplane-visualization-based-on-libsvm/">
                            SVM hyperplane visualization based on libsvm
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-06T09:24:10+08:00">
	
		    Mar 06, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>Support vector machine (SVM), as a shallow model, has been widely applied for classification tasks. To solve the model, groups of super vectors (SVs) of corresponding classes are extracted, so as to calculate a hyperplane as the classification boarder.</p>
<h3 id="A-brief-review"><a href="#A-brief-review" class="headerlink" title="A brief review"></a>A brief review</h3><p>Denote <script type="math/tex">\mathbf{x} = \{\mathbf{x_1},~\mathbf{x_2},~\dots,~\mathbf{x_N}\}</script> as the samples to be classified, and $y = \{y_1,~y_2,~\dots,~y_N\}$ are the corresponding labels. Take binary classification as an example, </p>
<script type="math/tex; mode=display">
\begin{equation}
    y_i(\mathbf{w}\cdot\mathbf{x_i}+b) \geq 1, i = 1,~2,~\dots,~N,
\end{equation}</script><p>where <script type="math/tex">\mathbf{w}</script> are the coefficients w.r.t. features in <script type="math/tex">\mathbf{x}</script>, b is the bias.</p>
<p>The the problem becomes an optimization task, where the object is,</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{cases}
    \min\limits_{w}\frac{\left \| \mathbf{w} \right \|}{2}, \\
    \mathrm{s.t.}~y_i(\mathbf{w}\cdot\mathbf{x_i}+b) \geq 1, i = 1,~2,~\dots,~N,
\end{cases}
\end{equation}</script><p>which shall be calculated with Lagrange equation,</p>
<script type="math/tex; mode=display">
\begin{equation}
L_P = \frac{1}{2}{\left\| \mathbf{w} \right \|} - \sum^{N}_{i=1}{\lambda_i\{y_i(\mathbf{w}\cdot\mathbf{x_i}+b)-1\}}.
\end{equation}</script><p>To save time, it usually selects a subset of <script type="math/tex">\mathbf{x}</script> namely super vectors to optimize above equation, instead of all of the samples. Those SVs are samples that stand close to the classification hyperplane, i.e., the boarders of different types. They are considered on behalf of the classes they belonging to.</p>
<p>By solving the Lagrange equation, we obtain the <script type="math/tex">\mathbf{\lambda}</script>, as well as <script type="math/tex">\mathbf{w}</script> and $b$.</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{cases}
    \mathbf{w} = \sum^{N_\rm{SV}}_{i=1}{\lambda_i y_i \mathbf{x_i}}, \\
    b = - \frac{1}{2}\mathbf{w}\cdot(\mathbf{x_{c1}}+\mathbf{x_{c2}}),
\end{cases}
\end{equation}</script><p>where <script type="math/tex">\mathbf{x_c1}</script> and <script type="math/tex">\mathbf{x_c2}</script> are arbitrary super vectors of class one and two, respectively.</p>
<p>The dicision function based on those parameters are,</p>
<script type="math/tex; mode=display">
\begin{equation}
    f(\mathbf{x_s}) = \rm{sgn}\left[ \sum^{N_\rm{SV}}_{i=1}{\lambda_i y_i (\mathbf{x_i}\cdot\mathbf{x_s}) + b} \right],
\end{equation}</script><p>here <script type="math/tex">\rm{sgn}</script> is the sign function.</p>
<p>For non-linear classification, which is more general than linear case, the dot product between <script type="math/tex">\mathbf{x_i}</script> and <script type="math/tex">\mathbf{x_s}</script> are replaced by non-linear kernel functions $\Phi(\cdot)$, i.e.,</p>
<script type="math/tex; mode=display">
\begin{equation}
    f(\mathbf{x_s}) = \rm{sgn}\left[ \sum^{N_\rm{SV}}_{i=1}{\lambda_i y_i \Phi(\mathbf{x_i},\mathbf{x_s})+b} \right].
\end{equation}</script><h3 id="Realization-and-visualization"><a href="#Realization-and-visualization" class="headerlink" title="Realization and visualization"></a>Realization and visualization</h3><p>With the help of <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank" rel="external">libsvm</a>, it is easy to realize SVM based classification. What I want to say in this blog is how to visualize or replicate the prediction stage of the <code>svmtrain</code> function. Some comments are as follows,</p>
<ul>
<li>After training the SVM with <code>svmtrain</code>, a <code>model</code> will be generated;</li>
<li>In the <code>model</code>, super vectors, parameters like weights and bias, are archived;</li>
<li><strong>To save space, the support vectors are saved as sparse matrix.</strong></li>
<li>For multi-class classification, it can be transformed to multiple binary-classification tasks.</li>
</ul>
<p>Here is a naive two-dimensional three-type classification example (<a href="https://github.com/myinxd/svm-toy/blob/master/demos/DrawSepLine3C.m" target="_blank" rel="external">code</a> is available). I divided three-class task into three binary classifications. The linear kernel function was used, thus the classification hyperplanes were also linear.</p>
<p><center>
<img src="https://github.com/myinxd/svm-toy/raw/master/images/fig_3c.png?raw=true" height="280" width="600">
</center><br>In the right figure, only support vector points are plotted. It can be found that the SVs are those points stand at the boarder between different categories.</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/06/svm-hyperplane-visualization-based-on-libsvm/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title" itemprop="headline">
                    
                        <a class="link-unstyled" href="/2018/03/04/a-numpy-matrix-copy-problem/">
                            Nupy矩阵的复制问题
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time itemprop="datePublished" datetime="2018-03-04T10:26:23+08:00">
	
		    Mar 04, 2018
    	
    </time>
    
</div>

            </div>
            
                <div class="postShorten-content" itemprop="articleBody">
                    <p>简单记录一下最近遇到的一个bug，利用numpy生成的矩阵在复制时不能直接赋值，而是要用<code>copy</code>方法。直接赋值类似于把内存中的地址 (即指针) 给了目标变量，其与被赋值变量共享同一块内存，这样做可以节省内存空间。而<code>copy</code>则不同，会重新申请一块内存，分配给复制后的新变量，在该变量上的操作不会对愿变量产生影响。</p>
<p>下面看一个例子,<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">x = np.arange(<span class="number">9.</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</div><div class="line"><span class="comment"># copy</span></div><div class="line">y = x.copy()</div><div class="line">y[y&gt;=<span class="number">5</span>] = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="comment"># 赋值法</span></div><div class="line">z = x</div><div class="line">z[z&gt;=<span class="number">5</span>] = <span class="number">0</span></div></pre></td></tr></table></figure></p>
<p>其输出结果如下,<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">In [<span class="number">6</span>]: y</div><div class="line">Out[<span class="number">6</span>]: </div><div class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</div><div class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>],</div><div class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</div><div class="line"></div><div class="line">In [<span class="number">7</span>]: x</div><div class="line">Out[<span class="number">7</span>]: </div><div class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</div><div class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</div><div class="line">       [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</div><div class="line"></div><div class="line">In [<span class="number">8</span>]: z</div><div class="line">Out[<span class="number">8</span>]: </div><div class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</div><div class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>],</div><div class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</div><div class="line"></div><div class="line">In [<span class="number">9</span>]: x</div><div class="line">Out[<span class="number">9</span>]: </div><div class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</div><div class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>],</div><div class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</div></pre></td></tr></table></figure></p>
<p>可以看到，采用<code>copy</code>后，对<code>y</code>的操作不会影响到原矩阵<code>x</code>，而采用直接赋值后，对<code>z</code>的操作对<code>x</code>产生了影响。</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/03/04/a-numpy-matrix-copy-problem/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
          <li class="pagination-prev">
            <a class="btn btn--default btn--small" href="/all-archives/">
              <i class="fa fa-angle-left text-base icon-mr"></i>
              <span>NEWER POSTS</span>
            </a>
          </li>
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="/all-archives/page/3/">
              <span>OLDER POSTS</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
        <li class="pagination-number">page 2 of 8</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2019 Jason Ma. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-remove"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Jason Ma</h4>
        
            <div id="about-card-bio"><p>We are in the same story.</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Astronomer? Software engineer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker"></i>
                <br/>
                Shanghai
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/script-peofhqjkzcghmndknakluequy1y6owxdwpaqyju9ntl9zxnk7rdolb3rjjoj.min.js"></script>
<!--SCRIPTS END--><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



    </body>
</html>
